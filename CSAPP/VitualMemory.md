# 虚拟内存

一个系统中的进程是与其他进程共享 CPU 和主存资源的。然后共享主存会形成一些特殊的挑战。如果太多的进程需要太多的内存，那么他中的一些根本就无法运行。为了更加有效的管理内存并且少出错，现在系统提供了一种对主存的抽象概念，叫做虚拟内存（VM）。虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件的完美交互，它为每个进程提供了一个大的、一致的和私有的地址空间。

- 1. 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。
- 2. 它为每个进程提供了一致的地址空间，从而简化了内存管理。
- 3. 它保护了每个进程不被其他进程破坏。

## 一、物理和虚拟寻址

计算机系统的主存被组织成一个由 M 个连续的自己大小的单元组成的数组。每个字节都有一个唯一的物理地址（Physical Address，PA）。第一个字节的地址为 0，接下来的字节地址为 1，再下一个为 2，以此类推。给定这种简单的结构，CPU 访问内存的最自然的方式就是使用物理地址。这种方式称为 **物理寻址**。早期的 PC 使用物理寻址，现代处理器使用一种称为 **虚拟寻址**（virtual addressing）的寻址方式，如图所示：

![image-20231106220237996](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231106220237996.png)

使用虚拟寻址，CPU 会通过生成一个 虚拟地址 来访问主存，这个虚拟地址在被送到内存之前先转换成适当的物理地址。将一个虚拟地址转换为物理地址的任务叫做 **地址翻译**。就像异常处理一样，地址翻译需要 CPU 硬件和操作系统之间的紧密合作。CPU 芯片上叫做内存管理单元（Memory Management Unit， MMU）的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。

## 二、地址空间

地址空间（address space）是一个非负整数地址的有序集合：
$$
{\{0, 1, 2, ···\}}
$$
如果地址空间中的整数是连续的，那么我们说它是一个线性地址空间。为了简化讨论，假设使用的都是线性地址空间。在一个带虚拟内存的系统中，CPU 从一个有 N = 2^n 个地址的地址空间生成虚拟地址，这个地址空间称为虚拟地址空间：
$$
{\{0,1,2,···, N - 1\}}
$$
一个地址空间的大小是由表示最大地址所需要的位数来描述的。例如，一个包含 N = 2^n 个地址的虚拟地址空间就叫做一个 n 位地址空间。现代系统通常支持 32 位或者 64 位虚拟地址空间。

一个系统还有一个物理地址空间，对应于系统中物理内存的 M 个字节：
$$
{\{0,1,2,···, M - 1\}}
$$
M 不要求是 2 的幂，但是为了简化讨论，假设 M = 2^m。

地址空间的概念很重要，因为它清楚地区分了数据对象（字节）和他们的属性（地址）。一旦认识到了这种区别，那么我们就可以将其推广，允许每个数据对象有多个独立的地址，其中每个地址都选自一个不同的地址空间，这是虚拟内存的基本思想。主存中的每个字节都有一个选自虚拟地址空间的虚拟地址和选自物理地址空间的物理地址。

## 三、虚拟内存作为缓存的工具

概念上而言，虚拟内存被组织为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组。每字节都有一个唯一的虚拟地址，作为到数组的索引。磁盘上数组的内容被缓存到主存上。和存储器层次结构中的其他缓存一样，磁盘（较低层）上的数据被分割为块，这些块 作为磁盘和主存（较高层）之间的传输单元。VM 系统通过将虚拟内存分割为称为**虚拟页（Virtual Page，VP）**的大小固定的块来处理这个问题。每个虚拟页的大小为 P = 2 ^ p 字节。类似的，物理内存被分割为**物理页（Physical Page，PP）**，大小也为 P 字节（物理页也被称为 页帧 ）。

在任意时刻，虚拟页面的集合都被分为三个不相交的子集：

- **未分配的：**VM 系统还未分配（或者创建）的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。
- **缓存的：**当前已缓存在物理内存中的已分配页。
- **未缓存的：**未缓存在物理内存中的已分配页。

下图展示了一个有 8 个虚拟页的小虚拟内存。虚拟页 0 和 3 还没有被分配，因此在磁盘上还不存在。虚拟页 1、4 和 6 被缓存在物理内存中。页 2、5 和 7 已经被分配了，但是当前还未缓存到主存中。

![image-20231106232739579](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231106232739579.png)

### 1. DRAM 缓存的组织结构

为了有助于清晰理解存储层次结构中不同的缓存概念，我们使用术语 **SRAM 缓存**来表示位于 CPU 和主存之间的 L1、L2 和 L3 高速缓存，并且用术语 DRAM 缓存来表示虚拟内存系统的缓存，他在主存中缓存虚拟页。

在存储层次结构中，DRAM 缓存的位置对它的组织结构有很大的影响。DRAM 比 SRAM 要慢大约 10 倍，而磁盘要比 DRAM 慢大约 100 000 多倍。因此，DRAM 缓存中的不命中比起 SRAM 缓存中的不命中要昂贵得多，这是因为 DRAM 缓存不命中要由磁盘来服务，而 SRAM 不命中通常由基于 DRAM 的主存来服务。而且，从磁盘的一个扇区读取第一个字节的时间开销比起读这个扇区中连续的字节要慢大约 100 000 倍。归根结底，DRAM 缓存的组织结构完全是由巨大的不命中开销驱动的。

因为巨大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是 4 KB ～ 2 MB。由于大的不命中处罚，DRAM 缓存是全相联的，即任何虚拟页都可以放置在任何物理页中。不命中的替换策略也很重要，因为替换错了虚拟页的处罚也非常之高。因此，与硬件对 SRAM 相比，操作系统对 DRAM 缓存使用了复杂精密的替换算法。最后，因为对磁盘访问的时间很长，DRAM 缓存总是使用写回，而不是直写。

### 2. 页表

同任何缓存一样，虚拟内存系统必须有某种办法来判定一个虚拟页是否缓存在 DRAM 中的某个地方。如果是，系统还必须确定这个虚拟页存放在哪个虚拟页中。如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页。

这些功能是由软硬件联合提供的，包括操作系统软件、MMU 中的地址翻译硬件和一个存放在物理内存中叫做**页表**的数据结构，页表将虚拟页映射到物理页。每次地址翻译将一个虚拟地址转换为物理地址时，都会读取页表。操作系统负责维护页表的内容，以及在磁盘与 DRAM 之间传送页。下图展示了一个页表的基本组织结构。页表就是一个页表条目（Page Table Entry，PTE）的数组。虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个 PTE。为了我们的目的，我们将假设每个 PTE 是由一个有效位和一个 n 位地址字段组成的。有效位表明了该虚拟页当前是否被缓存在 DRAM 中。如果设置了有效位，那么地址字段就表示 DTRAM 中相应的物理页的起始位置，这个物理页中缓存了该虚拟页。如果没有设置有效位，那么一个空地址表示这个虚拟页还没有被分配。否则，这个地址就指向该虚拟页在磁盘的起始位置。

图中展示了一个有 8 个虚拟页和 4 个物理页的系统的页表。四个虚拟页当前被缓存在 DRAM 中。两个页还没有被分配，而剩下的已经被分配了还没有被缓存。同时，还要注意，因为 DRAM 缓存时全相联的，所以任意物理页都可以包含任意虚拟页。

![image-20231107141326369](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107141326369.png)

### 3. 页命中

如下图所示，当 CPU 想要读取包含在 VP2 中的虚拟内存中的一个字时，如果 VP2 被缓存到 DRAM 中，使用地址翻译技术，地址翻译将虚拟地址作为一个索引来定位 PTE2，并在内存中读取它，因为设置了有效位，那么地址翻译硬件就知道 VP2 是缓存在内存中的，所以它使用 PTE 中的物理内存的地址（该地址指向 PP1 中缓存页的起始位置），构造出这个字的物理地址。

![image-20231107113516933](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107113516933.png)

### 4. 缺页

在虚拟内存的习惯说法中，DRAM 缓存不命中称为**缺页（page fault）**。下图展示了在缺页之前我们的示例页表的状态。CPU 引用了 VP3 中的一个字，VP3 并未缓存在 DRAM 中。地址翻译硬件从内存中读取 PTE3，从有效位推断出 VP3 未被缓存，并且触发一个缺页异常。缺页异常出发内核的缺页异常处理程序，该程序会选择一个牺牲页，在此示例中就是存放在 PP3 中的 VP4。如果 VP4 已经被修改了，那么内核就会将它复制回磁盘。无论哪种情况，内核都会修改 VP4 的页表条目，反映出 VP4 不再缓存在主存中这一事实。

![image-20231107114607922](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107114607922.png)

接下来，内核会从磁盘复制 VP3 到内存的 PP3 中，更新 PTE3，随后返回。当异常处理程序返回时，它会重新启动导致缺页的指令，该指令会把导致缺页的虚拟地址重发送到地址翻译硬件。但是现在，VP3 已经缓存到主存中了，那么页命中页命中也能由地址翻译硬件正常处理。，下图表示缺页之后的页表状态：

![image-20231107120126231](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107120126231.png)

虚拟内存系统使用了和 SRAM 缓存不同的术语，即使他们的许多概念是类似的。在虚拟内存的说法中，块被称之为页。在磁盘和内存之间传送页的活动叫做交换或者页面调度。页从磁盘换入 DRAM 和从 DRAM 换出磁盘。一直等待，直到最后时刻，也就是当有不命中发生时，才换入页面的这种策略称为按需页面调度。也可以采用其他的方法，例如尝试预测不命中，在页面实际被引用之前就换入页面。然后，所有现代系统都使用的是按需页面调度方式。

### 5. 分配页面

下图展示了操作系统分配一个新的虚拟内存页时对我们示例页表的影响，例如，调用 malloc 的结果。在这个示例中， VP5 的分配过程是在磁盘上创建空间并更新 PTE5，使它指向磁盘上新创建的页面。

![image-20231107141349552](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107141349552.png)

### 6. 局部性原理

我们了解了虚拟内存的概念以后，我们的第一印象通常是它的效率应该是非常低。因为不命中的处罚很大，我们担心页面调度会破坏程序的性能。实际上，虚拟内存工作的相当好，这主要归功于局部性原理。尽管在整个运行过程中程序引用的不同页面的总数可能超过物理内存的大小，但是局部性原则保证了在任意时刻，程序将趋向于在一个较小的活动页面的集合上工作，这个集合叫做工作集或者常驻集合。在初始开销，也就是将工作集页面调度到内存中之后，接下来对这个工作集的引用将导致命中，而不会产生额外的磁盘流量。只要程序有好的时间局部性，虚拟内存就会工作得相当好。但是，是不是所有程序都能展现良好的时间局部性，如果工作集的大小超出了物理内存的大小，那么程序就会产生一种不幸的状态，叫做抖动，这时页面将不断的换进换出。

## 四、虚拟内存作为内存管理的工具

到目前为止，我们都假设有一个单独的页表，将一个虚拟地址空间映射到物理地址空间。实际上，操作系统为每个进程提供了一个单独的页表，因而也就是一个独立的页表，因而也就是一个独立的虚拟地址空间。下图展示了基本思想。在这个示例中，进程 i 地页表将 VP1 映射到 PP2，VP2 映射到 PP7。相似地，进程 j 的页表将 VP1 映射到 PP7， VP2 映射到 PP10。注意，多个虚拟页面可以映射到同一个共享物理页面上。

![image-20231107141604674](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107141604674.png)

按需页面调度和独立的虚拟地址空间的结合，对系统中内存的使用和管理造成了深远的影响。特别地，VM 简化了链接和加载、代码和数据共享，以及应用程序的内存分配。

- 简化链接。独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。例如，一个给定的 Linux 系统上的每个进程都使用类似的内存格式。对于 64 位地址空间，代码段总是从虚拟地址 0x400000 开始。数据段跟在代码段之后，中间有一段符合要求的对齐空白。栈占据用户进程地址空间的最高的部分，并向下生长，这样的一致性极大的简化了链接器的设计和实现，允许链接器生成完全链接的可执行文件，这些可执行文件是独立于物理内存中代码和数据的最终位置的。

- 简化加载。虚拟内存还使得容易向内存中加载可执行文件和共享对象文件。要把目标文件中 .text 和 .data 节加载到一个新创建的进程中，Linux 加载器为代码和数据段分配虚拟页，把它们标记为无效的（即未被缓存的），将页表条目指向目标文件的适当位置。有趣的是，加载器从不从磁盘到内存实际复制任何数据。在每个页初次被引用时，要么是 CPU 取指令时引用的，要么是一条正在执行的指令引用一个内存位置时引用的。虚拟内存系统会按照需要自动地调入数据页。

    将一组连续的虚拟页映射到任意一个文件中的任意位置的表示方法叫做内存映射（mamory mapping）。Linux 提供一个称为 mmap 的系统调用，允许应用程序自己做内存映射。

- 简化共享。独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制。一般而言，每个进程都有自己私有的代码、数据、堆以及栈区域，是不和其他进程共享的。在这种情况中，操作系统创建页表，将相应的虚拟页映射到不连续的物理页面。

    然而，在一些情况下，还是需要进程来共享代码和数据。例如，每个进程必须调用相同的操作系统内核代码，而每个 c 程序都会调用 c 标准库中的程序，比如 printf。操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个副本，而不是每个进程都包括单独的内核和 c 标准库的副本。

- 简化内存分配。虚拟内存为向用户进程提供一个简单的分配额外内存的机制。当一个运行在用户进程中的程序要求额外的对空间时（如调用 malloc 的结果），操作系统分配一个适当数字（例如 k）个连续的虚拟内存页面，并且将它们映射到物理内存中任意位置的 k 个任意的物理页面。由于页表工作的方式，操作系统没有必要分配 k 个连续的物理内存页面。页面可以随机的分散在物理内存中。

## 五、虚拟内存作为内存保护的工具

任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问。不应该允许一个进程修改它的制度代码段。而且也不应该允许它读或者修改任何内核中的代码和数据结构。不应该允许它读或者写其他进程的私有内存，并且不允许它修改任何与其他进程共享的虚拟页面，除非所有的共享者都显式地允许它这么做（通过调用明确的进程间通信系统调用）。

就像我们所看到的，提供独立的地址空间使得区分不同进程的私有内存变得容易。但是，地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。因为每次 CPU 在生成一个地址时，地址翻译硬件都会读一个 PTE，所以通过在 PTE 上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单。如下图：

![image-20231107163141620](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107163141620.png)

在这个示例中，每个 PTE 中已经添加了三个许可位。SUP 位表示进程是否必须运行在内核（超级用户）模式下才能访问该页。运行在内核模式中的进程可以访问任何页面，但是运行在用户模式中的进程只允许访问那些 SUP 为 0 的页面。READ 位和 WRITE 位控制对页面的读和写访问。例如，如果进程 i 运行在用户模式下，那么它有读 VP0 和写 VP1 的权限，然后，不允许它访问 VP2。如果一条指令违反了这些许可条件，那么 CPU 就会触发一个保护故障，将控制传递给一个人内核中的异常处理程序，Linux shell 一般将这种异常报告为 **段错误（segment fault）**。

## 六、地址翻译

这一节讲述地址翻译的基础知识，目的是了解硬件在支持虚拟内存中的角色，并且给出足够多的细节使得可以亲手演示一些具体的示例。不过，这里省略了大量的细节，尤其是和时序相关的细节。下图包含了本节中要使用的所有符号：
![image-20231107193029468](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107193029468.png)

形式上来说，地址翻译是一个 N 元素的虚拟地址空间（VAS）中的元素和一个 M 元素的物理地址空间（PAS）中元素之间的映射，
$$
{MAP:VAS \rightarrow PAS\cup\emptyset}
$$
这里：

![image-20231107194224961](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107194224961.png)

下图展示了 MMU 如何利用页表来实现这种映射。CPU 中的一个控制寄存器，页表基址寄存器（Page Table Basic Register，PTBR）指向当前页表。n 位的虚拟地址包含两个部分：一个 p 位的虚拟页面偏移（Virtual Page Offset， VPO）和一个（n - p）位的虚拟页号（Virtual Page Number，VPN）。MMU 利用 VPN 来选择适当的 PTE。例如，VPN 0 选择 PTE 0，VPN 1 选择 PTE 1，以此类推。将页表条目的物理页号（PPN）和虚拟地址中的 VPO串联起来就得到对一个地址。注意，因为物理和虚拟页面都是 P 字节的，所以 PPO 和 VPO 也是相同的。

![image-20231107213205465](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107213205465.png)

下图展示了当页面命中和不命中时，CPU 硬件的执行步骤：

![image-20231107195905375](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107195905375.png)

当页面命中时：

1. 处理器生成一个虚拟地址，并把它传送给 MMU。
2. MMU 生成 PTE 地址，并从高速缓存/主存中请求得到它。
3. 高速缓存/主存向 MMU 返回 PTE。
4. MMU 构造物理地址，并把它传送给高速缓存/主存。
5. 高速缓存/主存返回请求的数据字给处理器。

当页面没有命中时：

1-3. 和命中时一样。

4. PTE 的有效位为 0，所以 MMU 出发一次异常，传递 CPU 中的控制到操作系统内核中的缺页异常处理程序。
5. 缺页处理程序确定出物理内存中的牺牲页，如果这个页面已经被修改了，则把它换出到磁盘。
6. 缺页处理程序页面调入新的页面，并更新内存中的 PTE。

### 1. 结合高速缓存和虚拟内存

在任何既使用虚拟内存又使用 SRAM 高速缓存的系统中，都有应该使用虚拟地址还是使用物理地址来访问 SRAM 高速缓存的问题。但是大多数系统还是选择物理寻址的。使用物理寻址，多个进程同时在高速缓存中有存储块和共享来自相同虚拟页面的块成为很简单的事情。而且，高速缓存无需处理保护问题，因为访问权限的检查是地址翻译的一部分。下图展示了一个物理寻址的高速缓存如何和虚拟内存结合起来。主要思路是地址翻译发生在高速缓存查找之前。注意，PTE 可以缓存，就像其他数据字一样。

![image-20231107213005648](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107213005648.png)

### 2. 利用 TLB 加速地址翻译

正如我们所看到的，每次 CPU 产生一个虚拟地址，MMU 就必须查阅一个 PTE，以便将虚拟地址翻译为物理地址。在最糟糕的情况下，这会要求从内存多取一次数据，代价是几十到几百个时钟周期。如果 PTE 碰巧缓存在 L1 中，那么开销就下降到 1～2 个时钟周期。然而，许多系统都试图消除即使是这样的开销，他们在 MMU 包括了一个关于 PTE 的小的缓存，称为 **翻译后备缓冲寄存器（Traslation Lookside Buffer，TLB）**。

![image-20231107212756729](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107212756729.png)

TLB 是一个小的、虚拟寻址的缓存，其中每一行都保存着一个由单个 PTE 组成的块。TLB 通常有高度的相联度。上图所示，用于组选择和行匹配的索引和标记字段是从虚拟地址中的虚拟页号中提取出来的。如果 TLB 有 T = 2^t 个组，那么 TLB 索引是由 VPN 的 t 个最低位组成的，而 TLB （TLBT）标记是由 VPN 中剩下的位组成的。

TLB 命中时的步骤：

1. CPU 产生一个虚拟地址。

2～3. MMU 从 TLB 中取出相应的 PLE。

4. MMU 将这个虚拟地址翻译成一个物理地址，并且将它发送到高速缓存/主存中。
5. 高速缓存/主存将所请求的数据字返回给 CPU。

当 TLB 不命中时，MMU 必须从 L1 缓存中取出相应的 PLE，如下图所示，新取的 PLE 放在 TLB 中，可能会覆盖一个已经存在的条目。

![image-20231107214338622](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107214338622.png)

### 3. 多级页表

到目前为止，我们一直假设系统只用一个单独的页表来进行地址翻译，但是如果我们有一个 32 位的地址空间，4KB 的页面，和一个 4 字节的 PLE，那么即使应用所引用的只是虚拟地址空间中的很小一部分，也总是需要一个 4MB 的页表驻留在内存中，对于地址空间为 64 位的系统，则问题更加复杂。

用来压缩页表的常用方法是使用层次结构的页表。用一个具体的示例是容易理解这个思想的。假设 32 位虚拟地址空间被分为 4KB 的页，而每个页表条目都是 4 字节。还假设在这一时刻，虚拟地址有如下形式：内存的前 2k 个页面分配给了代码和数据，接下来 6k 个页面还未分配，再接下来 1023 个页面也未分配，接下来的一个页面被分配给用户栈，下图展示了如何为这个虚拟地址空间构造一个两级的页表层次结构：

![image-20231109114127307](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231109114127307.png)

一级页面中的每个 PTE 负责映射虚拟地址空间中一个 4MB 的片（chunk），这里的每一个片都是由 1024 个连续的页面组成的。比如， PTE0 映射第一片，PTE1 映射接下来的一片，以此类推。假设地址空间是 4GB，1024 个 PTE 已经足够覆盖整个空间了。如果片 i 中的每个页面都未被分配，那么一级 PTE i 就为空。例如上图，片 2～7 是未被分配的。然而，如果片 i 中至少有一个页是分配了的，那么一级 PTE i 就指向一个二级页表的基址。例如，在图中，片 0，1，8的所有或者部分已被分配，所以他们的一级 PTE 指向二级页表。

二级页面的每一个 PTE 都负责映射一个 4KB 的虚拟内存页面，就像我们查看只有一级的页表一样。注意，使用 4 字节的 PTE，每个一级和二级页表都是 4KB 字节，这刚好和一个页面大小是一样的。这种方法从两个方面减少了内存要求。第一，如果一级页表中的一个 PTE 是空的，那么相应的二级页表就根本不会存在。这代表着一种巨大的潜在节约，因为对于一个典型的程序，4GB 的虚拟地址空间大部分是未分配的。第二，只有一级页表才需要总是在内存中；虚拟内存系统可以在需要时创建、页面调入或调出二级页表，这就减少了主存的压力；只有最经常使用的二级页表才需要缓存在主存中。

下图描述了使用 k 级页表层次结构的地址翻译。虚拟地址被划分为称为 k 个 VPN 和一个 VPO。每个 VPN i 都是一个到第 i 级页表的索引，其中 1 <= i <= k。第 j 级页表中的每个 PTE，1 <= j <= k-1，都指向第 j+1 级某个页表的基址。第 k 级页表中的每个 PTE 包含某个物理界面的 PPN ，或者某个磁盘块的地址，为了构造物理地址，在能够确定 PPN 之前，MMU 必须访问 k 个 PTE。对于只有一级的页表结构，PPO 和 VPO 是相同的。

![image-20231109163207686](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231109163207686.png)

### 4. 端到端的地址翻译

在这一节，我们通过一个具体的端到端的地址翻译示例，来综合一下我们上面学过的内容，这个示例运行在一个 TLB 和 L1 d-cache 的小系统上。为了保证可管理性，我们做出如下假设：

- 内存是按字节寻址的。
- 内存访问是访问 1 字节的字的（不是 4 字节的字）。
- 虚拟地址是 14 位长的（n = 14）。
- 物理地址是 12 位长的（m = 12）。
- 页面大小是 64 字节（P = 64）。
- TLB 是四路组相联的，总共有 16 个条目。
- L1 d-cache 是物理寻址、直接映射的，行大小为 4 字节，而总共有 16 个组。

下图展示了虚拟地址和物理地址的格式。因为每个页面是 2^6 = 64 字节，所以虚拟地址和物理地址的低 6 位分别作为 VPO 和 PPO。虚拟地址的高 8 位作为 VPN。物理地址的高 6 位作为 PPN。

![image-20231121235559945](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231121235559945.png)

下图展示了小内存系统的一个快照，包括 TLB、页表的一部分和 L1 高速缓存。在 TLB 个高速缓存的图上面，我们还展示了访问这些设备时硬件是如何划分虚拟地址和物理地址的位的。

- TLB。TLB 是利用 VPN 的位进行虚拟寻址的。因为 TLB 有 4 个组，所以 VPN 的低 2 位作为组索引（TLBI）。VPN 中剩下的高 6 位作为标记（TLBT），用来区别可能映射到同一个 TLB 组的不同的 VPN。
- 页表。这个页表是一个单级设计，一共有 2^8 = 256 个页表条目（PTE）。然而，我们只对这些条目中的开头 16 个感兴趣。为了方便，我们用索引它的 VPN 来标识每个 PTE；但是要记住这些 VPN 并不是页表的一部分，也不存储在内存中。另外，注意每个无效的PTE 的 PPN 都用一个破折号表示，以加强一个概念：无论刚好这里存储的是什么位值，都是没有任何意义的。
- 高速缓存。直接映射的缓存是通过物理地址中的字段来寻址的，因为每个块都是 4 字节，所以物理地址的低 2 位 作为块偏移（CO）。因为有 16 组，所以接下来的 4 位就用来表示组索引（CI）。剩下的 6 位作为标记（CT）。

![image-20231122000452063](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122000452063.png)

![image-20231122000513167](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122000513167.png)

给定了这种初始化设定，我们看党 CPU 执行一条读地址 0x03d4 处的字节的加载指令时会发生什么。（回想一下我们假定 CPU 读取 1 字节的字，而不是 4 字节的字）。

![image-20231122000715524](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122000715524.png)

开始时，MMU 从虚拟地址中抽取出 VPN（0x0F），并且检查 TLB，看它是否因为前面的某个内存引用缓存了 PTE 0x0F 的第二个条目中有效匹配，所以命中，然后将缓存的 PPN（0x0D）返回给 MMU。

如果 TLB 不命中，那么 MMU 就需要从主存取出相应的 PTE。然而，在这种情况中，我们很幸运，TLB 会命中。现在，MMU 有了形成物理地址所需要的所有东西。他通过将来自 PTE 的 PPN（0x0D）和来自虚拟地址的 VPO（0x14）连接起来，这就形成了物理地址（0x354）。

接下来，MMU 发送物理地址给缓存，缓存从物理地址中抽取出缓存偏移 CO（0x0）、缓存组索引 CI（0x5）以及缓存标记 CT（0x0D）。

![image-20231122001231408](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122001231408.png)

因为组 0x5 中的标记与 CT 相匹配，所以缓存检测到了一个命中，读出偏移量 CO 处的数据字节（ox36），并将它返回给 MMU，随后 MMU 将它传递回 CPU。翻译过程的其他路径也是可能的。例如，如果 TLB 不命中，那么就产生一个缺页，内核必须调入一个合适的页面，重新运行这条加载指令。另一种可能性时 PTE 是有效的，但是所需要的内存块在缓存中不命中。

## 七、案例研究：Intel Core i7/Linux 内存系统

### 1. Core i7 地址翻译

下图总结了完整的 Core i7 地址翻译过程，从 CPU 产生虚拟地址的时刻一直到来自内存的数据字到达 CPU。Core i7 采用四级页表层次结构。每个进程有他自己的私有的页表层次结构。当一个 Linux 进程在运行时，虽然 Core i7 体系结构允许页表换进换出，但是与已分配的页相关联的页表都是驻留在内存中的。CR3 控制寄存器指向第一级页表（L1）的起始位置，CR3 的值是每个进程上下文的一部分，每次上下文切换时，CR3 的值都会被恢复。

![image-20231122002111448](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122002111448.png)

![image-20231122002139505](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122002139505.png)

下图给出了第一级、第二级或第三级页表中条目的格式。当 P = 1 时（Linux 中就总是如此），地址字段包含一个 40 位物理页号（PPN），他指向适当的页表开始处。注意，这强加了一个要求，要求物理页表 4KB 对齐（因为 PPN 40 位，物理地址 52 位，所以 PPO 12 位，所以一个物理页的页面大小应该是 2 ^ 12 字节。

![image-20231122152427153](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122152427153.png)

下图给出了第四级页表中条目的格式。当 P = 1，地址字段包括一个 40 位 PPN，它指向物理内存中某一页的基地址。这又强加了一个要求，要求物理页表 4KB 对齐。

![image-20231122153921276](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122153921276.png)

PTE 有三个权限位，控制对页的访问。R/W 位确定页的内容是可以读写的还是只读的。U/S 位确定是否能够在用户模式中访问该页，从而保护操作系统内核中的代码和数据不被用户程序访问。XD（禁止执行）位是在 64 位系统中引入的，可以用来禁止从某些内存页取指令。这是一个重要的新特性，通过限制只能执行只读代码段，是的操作系统内核降低了缓冲区溢出攻击的风险。

当 MMU 翻译每一个虚拟地址时，它还会更新另外两个内核缺页处理程序会用到的位。每次访问一个页时，MMU 都会设置 A 位，称为**引用位**。内核可以用这个引用位来实现它的页替换算法。每次对一个页进行写之后，MMU 都会设置 D 位，又称修改位或者脏位。修改位告诉内核在复制替换页之前是否必须写回牺牲页。内核可以通过调用一条特殊的内核模式指令来清除引用位或者修改位。

下图给出 Core i7 MMU 如何使用四级的页表来将虚拟地址翻译成物理地址。36 位的 VPN 被划分为四个 9 位的片，每个片被用作到一个页表的偏移量，这个 PTE 包含 L2 页表的基地址。 VPN 2 提供了一个 L2 PTE 的偏移量，以此类推。

![image-20231122155307611](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122155307611.png)

> 优化地址翻译：
>
> 在对地址翻译的讨论中，我们描述了一个顺序的两个步骤的过程：
>
> 1. MMU 将虚拟地址翻译成物理地址。
> 2. 将物理地址传送到 L1 高速缓存。
>
> 然而，实际的硬件实现使用了一个灵活的技巧，允许这些步骤部分重叠，因此也就加速了对 L1 高速缓存的访问。例如，页面大小为 4KB 的 Core i7 系统丧的一个虚拟地址有 12 位的 VPO，并且这些位和相应物理地址中的 PPO 的 12 位是相同的。因为八路组相联、物理寻址的 L1 高速缓存有 64 个组和大小为 64 字节的缓冲块，每个物理地址有 6 个缓存偏移位个 6 个缓存索引位，这 12 位正好符合虚拟地址的 VPO 部分。当 CPU 需要翻译一个地址时，它就发送 VPN 到 MMU，发送 VPO 到 高速 L1 缓存。当 MMU 向 TLB 请求一个页表条目时，L1 高速缓存正忙着利用 VPO 位查找相应的组，并读出这个组里的 8 个标记和对应的数据字。当 MMU 从 TLB 得到 PPN 时，缓存已经准备好试着把这个 PPN 与这 8 个标记中的一个进行匹配。

### 2. Linux 虚拟内存系统

一个虚拟内存系统要求硬件和内核软件之间的紧密协作。Linux 为每个进程维护了一个单独的虚拟地址空间，形式如下图所示，我们已经多次看到过这幅图了，包括它那些熟悉的代码、数据、堆、共享库以及栈段。既然我们理解了地址翻译，就能够填入更多的关于内核虚拟内存的细节了，这部分虚拟内存位于用户栈之上。内核虚拟内存包含在内核中的代码和数据结构。内核虚拟内存的某些区域被映射到所有进程共享的物理页面。例如，每个进程共享内核的代码和全局数据结构。有趣的是，Linux 也将一组连续的虚拟页面（大小的关于系统中 DRAM 的总量）映射到相应的一组连续的物理页面。这就为内核提供了一种便利的方法来访问物理内存中任何特定的位置，例如，当它需要访问页表，或在一些设备上执行内存映射的 I/O 操作，而这些设备被映射到特定的物理内存位置时。

![image-20231122162049895](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122162049895.png)

内核虚拟内存的其他区域包含每个进程都不同的数据。比如说，页表、内核在进程中的上下文中执行代码时使用的栈，以及记录虚拟地址空间当前组织的各种数据结构。

#### (1) Linux 虚拟内存区域

Linux 将虚拟内存组织称一些区域（也叫做 段）的集合。一个区域就是已经存在着的（已分配的）虚拟内存的连续片（chunk），这些页是以某种方式相关联的。例如，代码段、数据段、堆、共享库段，以及用户栈都是不同的区域。每个存在的虚拟页面都保持在某个区域中，而不属于某个区域的虚拟页是不存在的，并且不能被进程引用。区域的概念很重要，因为它允许虚拟地址空间有间隙。内核不用记录那些不存在的虚拟页，而这样的页也不占用内存、磁盘或者内核本身中的任何额外资源。

下图强调了记录一个进程中虚拟内存区域的内核数据结构。内核为系统中的每个进程维护了一个单独的任务结构（源代码中的 task_struct）。任务结构中的元素包含或者指向内核运行该进程所需要的所有信息（例如，PID、指向用户栈的指针、可执行目标文件的名字，以及程序计数器）。

![image-20231122163715172](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122163715172.png)

任务结构中的一个条目指向 mm_struct，它描述了虚拟内存当前的状态。我们感兴趣的是两个字段 pgd 和 mmap，其中 pgd 指向第一级页表（页全局目录）的基址，而 mmap 指向一个 vm_area_structs（区域结构）的链表，其中每个 vm_area_structs 都描述了当前虚拟地址空间的一个区域。当内核运行这个进程时，就讲 pgd 存放在 CR3 控制寄存器中。

为了我们的目的，一个具体区域的区域结构包含下面的字段：

- vm_start：指向这个区域的起始处。
- vm_end：指向这个区域结束处。
- vm_port：描述这个区域内包含的所有页的读写许可权限。
- vm_flags：描述这个区域内的页面是与其他进程共享的，还是这个进程私有的（还描述了其他的一些信息）。
- vm_next：指向链表中的下一个区域结构。

####  (2) Linux 缺页异常处理

假设 MMU 在试图翻译某个虚拟地址 A 时，触发了一个缺页。这个异常导致控制转移到内核的缺页处理程序，处理程序随后就执行下面的步骤：

1. 虚拟地址 A 是合法的吗？换句话说，A 在某个区域结构定义的区域内吗？为了回答这个问题，缺页处理程序搜索区域结构的链表，把 A 和每个区域结构的 vm_start 和 vm_end 做比较。如果这个指令是不合法的，那么缺页处理程序就触发一个段错误，从而终止这个进程。这个情况在下图中标识为 “1”。

    因为一个进程可以创建任意数量的新虚拟区域（使用在下一节中描述的 mmap 函数），所以顺序搜索区域结构的链表花销可能会很大。因此在实际中，Linux 使用某些我们没有显示出来的字段，Linux 在链表中构建了一颗树，并在这棵树上进行查找。

2. 试图进行的内存访问是否合法？换句话说，进程是否有读、写或者执行这个区域内页面的权限？例如，这个缺页是不是由一条试图对这个代码段里的只读页面进行写操作的存储指令造成的？这个缺页是不是由一个运行在用户模式的进程试图从内核虚拟内存中读取字造成的？如果试图进行的访问不合法，那么缺页处理程序就触发一个保护异常，从而终止这个进程。这种情况在图中标识为 “2”。

3. 此刻，内核知道了这个缺页是由于对合法的虚拟地址进行合法的操作造成的。它是这样来处理这个缺页的：选择一个牺牲页面，如果这个牺牲页面被修改过，那么就将它交换出去，换入新的页面并进行更新页表。当缺页处理程序返回时，CPU 重新启动引起缺页指令，这条指令将再次发送 A 到 MMU。这次，MMU 就能正常的翻译 A，而不会再产生缺页中断了。

![image-20231122165648828](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122165648828.png)

## 八、内存映射

Linux 通过将一个虚拟内存区域与一个磁盘上的对象关联起来，以初始化这个虚拟内存区域的内容，这个过程称为**内存映射（mamory mapping）**。虚拟内存区域可以映射到两种类型的对象的一种：

1）Linux 文件系统中的普通文件：一个区域可以映射到一个普通磁盘文件的连续部分，例如一个可执行目标文件。文件区（section）被分成页大小的片，每一片包含一个虚拟页面的初始内容，因为按需进行页面调度，所以这些虚拟页面没有实际交换进入物理页面，直到 CPU 第一次引用到页面（即发射一个虚拟地址，落在地址空间这个页面的范围之内）。如果区域比文件区要大，那么就用 0 来填补这个区域余下的部分。

2）匿名文件：一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包含的都是二进制 0。CPU第一次引用这样一个区域内的虚拟页面时，内核就在物理内存中找到一个合适的牺牲页面，如果该页面被修改过，就将这个页面换出来，用二进制 0 覆盖牺牲页面并更新页表，将这个页面标记为是驻留在内存中的。注意在磁盘和内存之间是没有实际的数据传送的。因为这个原因，映射到匿名文件区域中的页面有时也叫作请求二进制 0 的页。

无论哪种情况，一旦一个虚拟页面被初始化了，它就在一个由内核维护的专门的交换文件之间换来换去，交换文件也叫做**交换空间**或者交换区域。需要注意的是，在任何时刻，交换空间都限制着当前运行的进程能够分配的虚拟页面的总数。

### 1. 再看共享对象

内存映射的概念来源于一个聪明的发现：如果虚拟内存系统可以集成到传统的文件系统中，那么就能提供一种简单而高效的把程序和数据加载到内存的办法。

正如我们所看到的，进程这一抽象能够为每个进程提供自己私有的虚拟地址空间，可以免受其他进程的错误读写。不过许多进程有同样的只读代码区域。例如每个运行 Linux shell 程序 bash 的进程都有相同的代码区域。而且，许多程序需要访问只读运行时库代码的相同副本。例如，每个 C 程序都需要来自标准 C 库诸如 printf 这样的函数，那么，如果每个进程都在物理空间保持着这些常用的代码的副本，那就是极端的浪费，幸运的是，内存映射给我们提供了一种清晰的机制，用来控制多个进程如何共享对象。

一个对象可以被映射到虚拟内存的一个区域，要么作为**共享对象**，要么作为**私有对象**。如果一个进程将一个共享对象映射到它的虚拟地址空间的一个区域内，那么这个进程对这个区域的任何写操作，对于那些也把这个共享对象映射到他们的虚拟内存的其他进程而言，也是可见的。而且，这些变化也会反映在磁盘的原始对象中。

另一方面，对于映射到私有对象的区域做的改变，对于其他进程来说是不可见的，并且进程对这个区域所做的任何写操作都不会反映在磁盘上的对象中。一个映射到共享对喜庆的虚拟内存区域叫做共享区域。类似的，也有私有区域。

假设进程 1 将一个共享对象映射到它的虚拟内存的一个区域中，如下图所示。现在假设进程 2 将同一个共享对象映射到它的地址空间（并不一定要和进程 1 在相同的虚拟地址处，如下图）。

![image-20231122174548822](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122174548822.png)

因为每个对象都有一个唯一的文件名，内核可以迅速的判定进程 1 已经映射了这个对象，而且可以使进程 2 中的页表条目指向相应的物理页面。关键点在于即使对象被映射到了多个共享区域，物理内存中也只需要存放共享对象的一个副本。为了方便，我们将物理页面显示为连续的，但是在一般情况下当然不是这样的。

私有对象使用一种叫**做写时复制**（copy-on-write）的巧妙技术被映射到虚拟内存中。一个私有对象开始生命周期的方式基本上与共享对象的一样，在物理内存中只保存私有对象的一份副本。比如，下图展示了一种情况，其中两个进程将一个私有对象映射到它们虚拟内存的不同区域，但是共享这个对象同一个物理副本。对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为只读，并且区域结构被标记为**私有的写时复制**。只要没有进程试图写它自己的私有区域，它们就可以继续共享物理内存中对象的一个单独副本。然而，只要有一个进程试图写私有区域内的某个页面，那么这个写操作就会触发一个保护故障。

当故障处理程序意识到保护异常是由于进程试图写私有的写时复制区域中的一个页面而引起的，它就会在物理内存中创建这个页面的一个新副本，更新页表条目指向这个新的副本，然后恢复这个页面的可写权限，如下图所示。当故障处理程序返回时，CPU 重新执行这个写操作，现在在新创建的页面上这个写操作就可以正常执行了。

![image-20231122180242946](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122180242946.png)

通过延迟私有对象中的副本直到最后可能的时刻，写时复制最充分地使用了稀有的物理内存。

### 2. 再看 fork 函数

既然我们理解了虚拟内存和内存映射，那么我们就可以清晰的知道 fork 函数是如何创建一个带有自己独立虚拟地址空间的新进程的。

当 fork 函数被当前进程调用时，内核为进程创建各种数据结构，并分配给它一个唯一的 PID。为了给这个新进程创建虚拟内存，他创建了当前进程的 mm_struct、区域结构和页表的原样副本。它将两个进程的每个页面都标记成只读，并将两个进程中的每个区域结构都标记成私有的写时复制。当 fork 在新进程返回时，新进程现在的虚拟内存刚好和调用 fork 时存在的虚拟内存相同。当这两个进程中的任一个后来进行写操作时，写时复制极致就会创建新页面，因此，也就为每个进程保持了私有地址空间的抽象概念。

### 3. 再看 execve 函数

虚拟内存和内存映射在将程序加载到内存的过程中也扮演着关键的角色。假设运行在当前进程中的程序执行了如下的 execve 调用：

```c
execve("a.out", NULL, NULL);
```

正如第八章所学的那样，execve 函数在当前进程中加载并运行包含在可执行目标文件 a.out 中的程序，用 a.out 中的程序有效的替代了当前程序。加载并运行 a.out 需要以下几个步骤：

- 删除已存在的用户区域。删除当前进程虚拟地址的用户部分中的已存在区域结构。
- 映射私有区域。为新程序的代码、数据、bss 和栈区域创建新的区域结构。所有这些新的区域都是私有的、写时复制的。代码和数据区域被映射为 a.out 文件中的 .text 和 .data 区。bss 区域是请求二进制 0 的，映射到匿名文件，其大小包含在 a.out 中。栈和堆区域也是请求二进制 0 的，初始长度为 0，下图概括了私有区域的不同映射。
- 映射共享区域。如果 a.out 程序与共享对象或目标链接，比如标准 C 库 libc.so，那么这些对象都是动态链接到这个程序的，然后再映射用户虚拟地址空间中的共享区域内。
- 设置程序计数器（PC）。execve 做的最后一件事情就是设置当前进程上下文中的程序计数器，使之指向代码区域的入口点。

下一次调度这个进程时，它将从这个入口点开始执行。Linux 将根据需要换入代码和数据页面。

![image-20231122182437537](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122182437537.png)

### 4. 使用 mmap 函数的用户级内存映射

Linux 进程可以使用 mmap 函数来创建新的虚拟内存区域，并将对象映射到这些区域中。

```c
#include <unistd.h>
#include <sys/mman.h>

void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);
// 返回：若成功时则为指向映射区域的指针，若出错则为 MAP_FAILED（-1）。
```

mmap 函数要求内核创建一个新的虚拟内存区域，最好是从地址 start 开始的一个区域，并将文件描述符 fd 指定的对象的一个连续的片（chunck）映射到这个新的区域。连续的对象片大小为 length 字节，从距文件开始处偏移量为 offset 字节的地方开始。start 地址仅仅是一个暗示，通常被定义为 NULL。为了我们目的，我们总是假设其实地址为 NULL。下图描述了这些参数的意义。

![image-20231122183605394](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231122183605394.png)

参数 proct 包含描述新映射的虚拟内存区域的访问权限位（即在相应区域结构中的 vm_proct 位）。

- PROT_EXEC：这个区域内的页面由可以被 CPU 执行的指令组成。
- PROT_READ：这个区域内的页面可读。
- PROT_WRITE：这个区域内的页面可写。
- PROCT_NONE：这个区域内的页面不能被访问。

参数 flags 由描述被映射对象类型的位组成。如果设置了 MAP_ANON 标记位，那么被映射的对象就是一个匿名对象，而相应的虚拟页面是请求二进制 0 的。MAP_SHARED 表示一个共享对象，MAP_PRIVATE 表示被映射的对象是一个共享对象。例如：

```c
bufp = Mmap(NULL, size, PROT_READ, MAP_PRIVATE|MAP_ANON, 0, 0);
```

让内核创建了一个新的包含 size 字节的只读、私有、请求二进制 0 的虚拟内存区域。如果调用成功，那么 bufp 包含新区域的地址。

munmap 函数删除虚拟内存区域：

```c
int munmap(void *start, size_t length);
// 返回：若成功，则返回 0，若出错则为 -1。
```

munmap 函数删除从虚拟地址 start 开始的，由接下来 length 字节组成的区域，接下来对已删除区域的引用会导致段错误。

## 九、动态内存分配

虽然可以使用低级的 mmap 和 munmap 函数来创建和删除虚拟内存的区域，但是 C 程序还是会觉得当运行时需要额外的虚拟内存时，用动态内存分配器（dynamic memory allocator）更方便，也有更好的移植性。动态内存分配器维护着一个进程的虚拟内存区域，称为堆（heap），系统之间的细节不同，但是不失通用性，假设堆是一个请求二进制 0 的区域，他紧接着在未初始化的数据区域后开始，并向上生长（向更高的的地址）。对于每个进程，内核维护着一个变量 brk（读作 break），它指向堆的顶部。

分配器将堆视为一组大小不同的块（block）的集合来维护。每个块就是一个连续的虚拟内存片（chunk），要么是已分配的，要么是空闲的。已分配的块显示地保留为供应用程序使用。空闲块可用来分配。空闲块保持空闲，直到它显式地被应用所分配。一个已分配的块保持已分配状态，直到它被释放，这种释放要么是应用程序显式执行的，要么是内存分配器隐式执行的。

分配器有两种基本风格。两种风格都要求应用显式地分配块。它们的不同之处在于由哪个实体来负责释放已分配的块。

- 显式分配器（explicit allocator），要求应用显式地释放任何已分配的块。例如，C 标准库提供一种叫做 malloc 程序包的显式分配器。C 程序通过调用 malloc 函数来分配一个块，并通过调用 free 来释放一个块。C++ 中的 new 和 delete 操作符与 C 语言中的 malloc 和 free 相当。
- 隐式分配器（implicit allocator），另一方面，要求分配器检测一个已分配块何时不再被程序所使用，那么就释放这个块。隐式分配器也叫做垃圾收集器（garbage collector），而自动释放未使用的已分配的块叫做过程叫做垃圾收集（garbage collection）。例如，诸如 Lisp、ML 以及 Java 之类的高级程序语言就依赖垃圾收集来释放已分配的块。

为了更具体，我们的讨论集中于管理堆内存的分配器。然而，应该明白内存分配是一个普遍的概念，可以出现在各种上下文中。例如，图形处理密集的应用就经常使用标准分配器来要求获得一大块虚拟内存，然后使用与应用相关的分配器来管理内存，在该块中创建和销毁图形的节点。

### 1. malloc 和 free 函数

```c
void *malloc(size_t size);
// 返回：若成功，则为已分配的块的指针，若出错则为 NULL。
```

malloc 函数返回一个指针，指向大小为至少是 size 字节的内存块，这个块会为可能包含在这个块内的任何数据对象做对齐。实际上，对齐依赖于编译代码在 32 位模式（gcc-m32）还是 64 位模式（默认的）中运行的。在 32 位模式中，malloc 返回的块的地址是 8 的倍数，在 64 位模式中，返回的地址总是 16 的倍数。

> 回想之前在对机器代码的讨论中，Intel 将 4 字节对象称为双字。然而在本节中，我们会假设字是 4 字节的对象，而双字节是 8 字节的对象。

如果 malloc 遇到问题（例如程序要求的内存块比可用的虚拟内存还要大），那么它就会返回 NULL，并设置 errno。malloc 不初始化它返回的内存。那些想返回要已初始化的动态内存的应用程序可以使用 calloc，calloc 是一个基于 malloc 的瘦包装函数，它将分配的内存初始化为 0，想要改变一个以前已经分配块的大小，可以使用 realloc 函数。

动态内存分配器，例如 malloc ，可以通过使用 mmap 和 munmap 函数，显式的分配和释放堆内存，或者还可以使用 sbrk 函数：

```c
void *sbrk(intptr_t incr);
// 返回：若成功则为旧的 brk 指针，若出错则为 -1。
```

sbrk 函数通过将内存的 brk 指针增加 incr 来扩展和收缩堆。如果成功，它就返回 brk 的旧值，否则，它就返回 -1，并将 errno 设置 ENOMEM。如果 incr 为 0，那么 sbrk 就返回当前 brk 的值。用一个负的 incr 来调用 sbrk 是合法的，返回值指向（brk 旧值）距新堆顶向上  abs（incr）字节处。

程序通过 free 函数释放已分配的堆块。

```c
void free(void *ptr);
```

ptr 参数必须指向一个从 malloc、calloc 或者 realloc 获得的已分配块的起始位置。如果不是，那么 free 的行为就是未定义的。更糟的是，既然他什么都不返回，free 不会告诉应用出现了错误，这会产生一些令人迷惑的运行时错误。

下图展示了一个 malloc 和 free 的实现是如何管理一个 C 程序的 16 字节的（非常）小的堆的。每个方框代表了一个 4 字节的字。粗线标出的矩形对应于已分配的块（有阴影的）和空闲块（无阴影的）。初始时，堆是由一个大小为 16 个字、双字对齐、空闲块组成的。在本节中，我们假设分配器返回的块是 8 字节双字边界对齐的。）

![image-20231124115527165](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231124115527165.png)

- 图 9-34a ：程序请求一个 4 字的块。malloc 的响应是：从空闲块的前部切出一个 4 字的块，并返回指向这个块的第一个字的指针。
- 图 9-34b ：程序请求一个 5 字的块。malloc 的响应是：从空闲块的前部分配一个 6 字的块。在本例中，malloc 在块里填充了一个额外的字，是为了保持空闲块是双字边界对齐的。
- 图 9-34c ：程序请求一个 6 字的块，而 malloc 就从空闲块的前部切出一个 6 字块。
- 图 9-34d ：程序释放在 图 9-34b 中分配的那个 6 个字的块。注意，在调用 free 返回之后，指针 p2 仍然指向被释放了的块。应用有责任在它被一个新的 malloc 调用重新初始化之前，不再使用 p2。
- 图 9-34e ：程序请求一个 2 字的块。这这种情况中，malloc 分配在前一步中被释放了的块的一部分，并返回一个指向这个新块的指针。

### 2. 为什么使用动态内存分配

程序使用动态内存分配的最重要的原因是经常直到应用实际运行时，才知道某些数据结构的大小。

### 3. 分配器的要求和目标

显式分配器必须在一些相当严格的约束条件下工作：

- 处理任意请求序列。一个应用可以有任意的分配请求和释放请求序列，只要满足约束条件：每个释放请求必须对应于一个当前已经分配块，这个块是由一个以前的分配请求获得的。因此，分配器不可以假设分配和释放请求的顺序。例如，分配器不能假设所有的分配请求都有对应的释放请求，或者有相匹配的分配和空闲请求是嵌套的。
- 立即响应请求。分配器必须立即响应分配请求。因此，不允许分配器为了提高性能重新排列或者缓冲请求。
- 只使用堆。为了使分配器是可扩展的，分配器使用的任何非标量数据结构都必须保存在堆里。
- 对齐块（对齐要求）。分配器必须对齐块，使得他们可以保存任何类型的数据对象。
- 不修改已分配的块。分配器只操作或者修改空闲的块。特别是，一旦块被分配了，就不再允许修改或者移动它了。因此，诸如压缩已分配块这样的技术是不允许使用的。

在这些限制条件下，分配器的编写者试图实现吞吐率最大化和内存利用率最大化，而这两个性能目标通常是互相冲突的。

- 目标一：最大化吞吐率。假定 n 个分配和释放请求的某种序列：
    $$
    {R_0,R_1,···,R_k,···,R_{n-1}}
    $$
    我们希望分配器的吞吐率最大化，吞吐率的定义为每个单位时间里完成的请求数。例如，如果一个分配器在 1 秒内完成 500 个分配请求和 500 个释放请求，那么它的吞吐率就是每秒 1000 次操作。一般而言，我们可以通过使满足和释放请求的平均时间最小化来使吞吐率最大化。正如我们会看到的那样，开发一个具有合理性能的分配器并不困难，所谓合理性能是指一个分配请求的最糟运行时间与空闲块的时间成线性关系，而释放一个请求的运行时间是一个常数。

- 目标二：最大化内存利用率。天真的程序员经常不正确的假设虚拟内存是一个无限的资源。实际上，一个系统中被所有进程分配的虚拟空间的全部数量是受磁盘上交换空间的数量限制的。好的程序员知道虚拟是一个有限的空间，必须高效的使用。对于可能被要求分配和释放大块内存空间的分配器来说，尤其如此。

有很多方式来描述一个分配器使用堆的效率如何。在我们的经验中，最有用的标准是 **峰值利用率（peak utilization）**。像以前一样，我们给定 n 个分配和释放请求的某种顺序：
$$
{R_0,R_1,···,R_k,···,R_{n-1}}
$$

如果一个应用程序请求一个 p 字节的块，那么得到的已分配块的**有效载荷（payload）**是 p 字节。在请求 ${R_k}$ 完成之后，聚集有效载荷表示为 ${P_k}$ ，为当前已分配块的有效载荷之和，而 ${H_k}$ 表示堆当前的（单调非递减的）大小。那么前 k+1 个请求的峰值利用率，表示为 ${U_k}$，通过下式得到：
$$
{U_k = {{max_{i \leq k} P_i} \over {H_k}}}
$$
那么，分配器的目标就是在整个序列中使峰值利用率 ${U_{n-1}}$ 最大化。正如我们将看到的那样，在最大化吞吐率个最大化利用率之间是相互牵制的。特别是，一堆利用率为代价，很容易编写出吞吐率最大化的分配器。分配器设计中一个有趣的挑战就是在两个目标之间找到一个合适的平衡。

> 放宽单调性假设：
>
> 我们可以通过让 ${H_k}$ 称为前 k+1 个请求的最高峰，从而使得在我们对 ${U_k}$ 的定义中放宽单调非递减的假设，并且允许堆增加和降低。

### 4. 碎片

造成堆利用率很低的主要原因是一种称为碎片（fragmetation）的现象，当虽然有未使用的请求但是无法满足分配请求时，就发生这种现象。有两种形式的碎片：内部碎片（internal fragmentation）和外部碎片（external fragmentation）。

内部碎片是在一个已分配内存块比有效载荷大时发生的。很多原因都会导致这个问题。例如，一个分配器的实现可能对已分配块强加一个最小的大小值，而这个大小要比某个请求的有效载荷大。或者，如我们在 图 9-34b 中看到的那样，分配器可能增加块大小以满足对齐约束要求。

内部碎片的量化是简单明了的。它就是已分配块大小和它们的有效载荷大小之差的和。因此，在任意时刻，内部碎片的数量只取决于以前请求的模式和分配器的实现方式。

外部碎片是当空闲内存合计起来足够满足一个分配请求，但是没有一个单独的空闲块足够大可以来处理这个请求时发生的。例如，如果图 9-34e 中的请求要请求 6 个字，而不是 2 个字，那么如果不向内核请求额外的虚拟内存的空间就无法满足这个请求。即使在堆中仍然有 6 个空闲的字。问题的产生是这 6 个字是分散在两个空闲块之间的。

外部碎片比内部碎片的量化要困难得多，因为它不仅取决于以前请求的模式和分配器的实现方式，还取决于将来的请求模式。因为外部碎片难以量化且不可预测，所以分配器通常采用启发式的策略来试图维持少量的大空闲块，而不是维持大量小的空闲块。

### 5. 实现问题

可以想象出最简单的分配器会把堆组织成一个大的字节数组，还有一个指针 p，初始指向这个数组的第一个字节。为了分配这个 size 个字节，malloc 将 p 的当前值保存在栈里，将 p 增加 size，并将 p 的旧值返回到调用函数。free 函数只是简单地返回到调用函数，而不做其他事情。

这个简单的分配器是设计中的一个极端情况。因为每个 malloc 和 free 只执行少量的指令，吞吐率会极好，然而因为分配器从不重复使用任何块，内存利用率将极差。一个实际的分配器要在吞吐率和利用率之间把握好平衡，就必须考虑下面几个问题：

- 空闲块组织：我们如何记录空闲块？
- 放置：我们如何选择一个合适的空闲块来放置一个新分配的块？
- 分割：在将一个新分配的块放置到空闲块之后，我们如何让处理这个空闲块中的剩余部分？
- 合并：我们如何让处理一个刚刚被释放的块？

本节剩下的内容将更详细的讨论这些问题。因为像放置、分割以及合并这样的基本技术贯穿在许多不同的空闲块组织中，所以我们将在一种叫做隐式空闲链表的简单空闲块组织结构中来介绍他们。

### 6. 隐式空闲链表

任何实际的分配器都需要一些数据结构，允许它来区别块边界，以及区别已分配块和空闲块。大多数分配器将这些信息嵌入块本身。一个简单的方法如图所示：

![image-20231124173841256](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231124173841256.png)

在这种情况下，一个块是由一个字的头部、有效载荷，以及可能的一些额外的填充组成的。头部编码了这个块的大小（包括头部和所有的填充），以及这个块是已分配还是空闲的。如果我们强加一个双字的对齐的约束要求，那么块的大小就总是 8 的倍数，且块大小的最低三位总是 0。因此我们只需要内存大小的 29 个高位，释放剩余的 3 位来编码其他信息。在这种情况下，我们用其中的最低位（已分配位）来指明这个块是已分配的还是空闲的。例如，假设我们有一个已分配的块，大小为 24（0x18）字节。那么它的头部将是：

0x00000018 | 0x1 = 0x00000019	

类似地，一个块大小为 40（0x28）字节的空闲块有如下的头部：

0x00000028 ｜0x0 = 0x00000028

头部后面就是应用调用 malloc 时请求的有效载荷。有效载荷后面是一片不使用的填充块，其大小可以是任意的。需要填充的原因有很多。比如，填充可能是分配器策略的一部分，用来对付外部碎片。或者也需要用它来满足对齐要求。

假设块的结构如下图所示，我们可以将堆组织为一个连续的已分配块和空闲块的序列，如下图所示：

![image-20231124180002013](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231124180002013.png)

我们称这种结构为隐式空闲链表，是因为空闲块是通过头部中的大小字段隐含地连接着的。分配器可以通过遍历堆中所有块，从而间接地遍历整个空闲块的集合。注意，我们需要某种特殊标记的结束块，在这个示例中，就是一个设置了已分配位而大小为 0 的终止头部（terminating header）。

隐式空闲链表的优点是简单。显著的缺点是任何操作的开销，例如防止分配的块，要求对空闲链表进行搜索，该搜索所需时间与堆中已分配块和空闲块的总数成线性关系。很重要的一点就是意识到系统对齐要求和分配器对块格式的选择会对分配器上的最小块大小有强制要求。没有已分配块或者空闲块可以比这个最小值还小。例如，我们假设一个双字的对齐要求，那么每个块的大小都必须是双字（8 字节）的倍数。因此 图9-35 中的格式就导致最小的块大小为两个字：一个字做头，另外一个字维持对齐要求。即使应用只请求一个字节，分配器仍然需要创建一个两字的块。

### 7. 放置已分配的块

当应用请求一个 k 字节的块时，分配器搜索空闲链表，查找一个足够大可以放置搜请求的块的空闲块。分配器执行这种搜索的方式是由放置策略（placemant policy）确定的。一些常见的策略是首次适配（first fit）、下一次适配（next fit）和最佳适配（best fit）。

**首次适配**从头开始搜索空闲链表，选择第一个合适的空闲块。**下一次适配**和首次适配很相似，只不过不是从链表的起始处开始每次搜索，而是从上一次查询结束的地方开始。**最佳适配**检查每个空闲块，寻阿泽适合所需请求大小的最小空闲块。

首次适配的优点是它趋向于将大的空闲块保留在链表的后面。缺点是它趋向于在靠近链表的起始处留下小空闲块的“碎片”，这就增加了对较大块的搜索时间。下一次适配是作为首次适配的一种替代品提出的，源于这样的一个想法：如果我们上一次在某个空闲块已经发现了一个匹配，那么很可能下一次我们也能在这个剩余块中发现匹配。下一次适配首次适配运行起来明显快一点，尤其是当链表前面布满了许多小的碎片时。然而，一些研究表明，下一次适配的内存利用率比首次适配要低得多。研究还表明最佳适配比首次适配和下一次适配的内存利用率都高一些。然而，在简单空闲链表组织结构中，比如隐式空闲链表中，使用最佳适配的缺点是它要求对堆进行彻底的搜索。在后面，我们将看到更加精细复杂的分离式空闲链表组织，他接近于最佳适配策略，不需要进行彻底的堆搜索。

### 8. 分割空闲块

一旦分配器找到一个匹配的空闲块，它就必须做另一个策略决定，那就是分配这个空闲块中多少空间。一个选择是用整个空闲块。虽然这种方式简单快捷，但是主要缺点是会造成内存碎片。如果放置策略趋向于产生好的匹配，那么额外的内部碎片也是可以接受的。然而，如果匹配不太好，那么分配器通常会选择将这个空闲块分割成两部分，第一部分变成分配块，而剩下的变成了一个新的空闲块。下图展示了分配器如何分割 图9-36 中的 8 个字的空闲块，来满足一个应用对堆内存 3 个字的请求。

![image-20231124213441463](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231124213441463.png)

### 9. 获取额外的堆内存

一旦分配器不能为请求块找到合适的空闲块会发生什么呢？一个选择是通过合并那些在内存中物理上相邻的空闲块来创建一个更大的空闲块（在下一节描述）。然而，如果这样还是不能生成一个足够大的块，或者如果空闲块已经最大程度地合并了，那么分配器将额外的内存转化成一个大的空闲块，将这个块插入到空闲链表中，最后将被请求的块放进新的空闲块中。

### 10. 合并空闲块

当分配器释放一个分配块时，可能有其他空闲块与这个新释放的空闲块相邻。这些邻接的空闲块可能引起一种现象，叫做 **假碎片（fault fragmentation）**，就是有许多可用的空闲块被切割成小的、无法使用的空闲块。比如下图展示了释放 图9-37 中的分配的块得到的结果。结果是两个相邻的空闲块，每一个的有效载荷都为 3 个字。因此，接下来一个对 4 字有效载荷的请求就会失败，即使两个空闲块的合集大小足够大，可以满足这个请求。

![image-20231124212530232](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231124212530232.png)

为了解决假碎片问题，任何实际的分配器都必须合并相邻的空闲块，这个过程称为 **合并**（coalescing）。这就出现了一个重要的策略决定，那就是何时执行合并。分配器可以选择立即合并，或者它也可以推迟合并，直到某个请求失败，然后扫描整个堆，合并所有的空闲块。立即合并很简单明了，可以在常数时间内完成，但是对于某些请求模式，这种方式会产生一种形式的抖动，块会被反复的合并，然后马上分割。例如，在 图9-38 中，反复的分配和释放一个 3 个字 的块将产生大量不必要的分割合并。在对分配器的讨论中，我们会假设使用立即合并，但是应该了解到，快速的分配器通常会选择某种形式的推迟合并。

### 11. 带边界标记的合并

分配器是如何实现合并的？我们称想要释放的块为当前块，那么合并下一个空闲块简单而且高效。但是该如何合并前面的块？给定一个带头部的隐式空闲链表，唯一的选择就是搜索恩哥链表，记住前面一个块的位置，直到我们到达当前块。使用隐式空闲链表，这意味着每次调用 free 需要的时间都与堆的大小成线性关系。即使使用更加复杂精细的空闲链表组织，搜索时间也不是常数。

一种聪明且通用的技术叫做边界标记（boundary tag），允许在常数时间内进行对前面块的合并。这种思想，如下图所示，在每个块的结尾处添加一个**脚部**（footer，边界标记），其中脚部就是头部的一个副本。每个块都包括这样一个脚部，那么分配器可以通过检查脚部，判断前一个块的起始位置和状态，这个脚部总是距当前块开始位置一个字的距离。

考虑释放当前块时所有可能存在的情况：

1. 前面的块和后面的块都是已分配的。
2. 前面的块已分配，后面的块时空闲的。
3. 前面的块是空闲的，后面的块是已分配的。
4. 前面和后面的块都是空闲的。

下图展示了我们如何对这四种情况进行合并：

![image-20231124214959892](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231124214959892.png)

边界标记的概念是简单优雅的，它对许多类型的分配器和空闲链表组织都是通用的，然后它要求每个块都保持一个头部和一个脚部，在应用程序操作许多个小块时，会产生显著的内存开销。例如反复调用一个两个字的内存，那么头部和脚部会占用一般的开销。

幸运的是，有一种非常聪明的边界标记的优化方法，能够使得在已分配块中不再需要脚部。回想一下，当我们试图在内存中合并当前块以及前面的还有后面的块时，只有当前一个块是空闲时，才会需要用到它的脚部，如果我们把前面块的已分配/空闲位存放在当前块多出来的低位上，那么已分配的块就不需要脚部了，可以把这个多出来的字做有效载荷，不过当前一个块时空闲块时，仍然需要脚部。

### 12. 综合：实现一个简单的分配器

构造一个分配器是一件富有挑战性的任务。设计空间很大，有多种块格式、空闲链表格式，以及放置、分割和合并策略可供选择。另一个挑战就是你经常被迫在类型系统的安全和熟悉的限定之外编程，依赖于容易出错的指针强制类型转换的指针运算，这些操作都是属于典型的底层系统编程。

我们基于隐式空闲链表，使用立即边界标记合并方式，从头至尾地讲述一个简单分配器的实现。最大的块大小为 2^32 = 4GB。代码是 64 位干净的，即代码能不加修改地运行在 32 位（gcc-m32）或 64 位（gcc-m64）的进程中。

#### （1）通用分配器设计

我们的分配器使用如下所示的 memlib.c 包所提供的一个内存系统模型。模型的目的在于允许我们在不干涉已存在的系统层的包的情况下，运行分配器。

```c
// private global variables
static char *mem_heap;		// Points to first byte of heap
static char *mem_brk;			// Points to last byte of heap plus 1
static char *mem_max_addr	// Max legal heap addr plus 1
  
// mem_init - Initialize the memory system model
void mem_init(void) {
  mem_heap = (char *)Malloc(MAX_HEAP);
  mem_brk = (char *)mem_heap;
  mem_max_addr = (char *)(mem_heap + MAX_HEAP);
}

// mem_sbrk - Simple model of the sbrk function. Extends the heap by intr bytes	and
// 						returns the start address of the new area. In this model, the heap cannot be shrunk.
void *mem_sbrk(int intr) {
  char *old_brk = mem_brk;
  
  if((intr < 0) || (mem_brk + intr) > mem_max_addr) {
    errno = ENOMEM;
    fprintf(stderr, "ERROR: mem_sbrk failed. Ran out of memory...\n");
    return (void *)-1;
  }
  mem_brk += intr;
  return (void *)old_brk;
}
```

mem_init 函数将对于堆来说可用的虚拟内存模型化为一个大的、双字对齐的字节数组。在 mem_heap 和 mem_brk 之间的字节表示已分配的虚拟内存。mem_brk 之后的字节表示未分配的虚拟内存。分配器通过调用 mem_sbrk 函数来请求额外的堆内存。这个函数和系统的 sbrk 函数的接口相同，而且语义也相同，除了他会拒绝收缩堆的请求。分配器包含在一个源文件中（mm.c），用户可以编译和链接这个源文件到他们的应用之中。分配器输出三个函数到外部：

```c
extern int mm_init(void);
extern void *mm_malloc(size_t size);
extern void mm_free(void *ptr);
```

- mm_init 函数初始化分配器，如果成功则为 0，不成功就返回 -1。
- mm_malloc 和 mm_free 函数与它们对应的系统函数有相同的接口和语义。

分配器使用如 图9-39 所示的块格式。最小块的大小为 16 字节（4 字）。空闲链表组织成为一个隐式空闲链表，具有如下图所示的恒定形式：

![image-20231125150105003](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231125150105003.png)

第一个字是一个双字边界对齐的不使用的填充字。填充后面紧跟着一个特殊的序言块（prologue block），这是一个 8 字节的已分配块，只由一个头部和一个脚部组成。序言块是在初始化时创建的，并且永不释放。在序言块后面紧跟着的是 0 个或者多个由 malloc 或者 free 调用创建的普通块。堆总是以一个特殊的结尾块来结束，这个块是一个大小为 0 的已分配块，只有一个头部组成。序言块和结尾块是一种消除合并时边界条件的技巧。分配器使用一个单独的私有（static）全局变量（heap_listp），它总是指向序言块。（作为一个小优化，我们可以让它指向下一个块，而不是这个序言块。）

#### （2）操作空闲链表的基本常数和宏

下图展示了一些我们在分配器编码中将要使用的基本常数和宏。

![image-20231125151849308](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231125151849308.png)

第 2-4 行定义了一些基本的大小常数：字的大小（WSIZE）和双字的大小（DSIZE），初始空闲块的大小和扩展堆时的默认大小（CHUNKSIZE）。在空闲链表中操作头部和脚部可能是很麻烦的，因为它要求大量使用强制类型转换和指针运算。因此我们发现定义以小组宏来访问和遍历空闲链表是很有帮助的（第 9-25行）。

- PACK 宏将大小和已分配位结合起来并返回一个值，可以把它保存到头部或脚部中。
- GET 宏读取和返回参数 p 引用的字。这里强制类型转换是很重要的，参数 p 是一个 void* 指针，不可以直接进行间接引用。类似地，PUT 宏将 val 存放在参数 p 所指向的字中。
- GET_SIZE 和GET_ALLOC 宏从地址 p 处的头部或者脚部分别返回大小和已分配位。
- 剩下的宏是对块指针（block pointer，用 bp 表示）的操作，块指针指向第一个有效载荷的字节。

#### （3）创建初始空闲链表

在调用 mm_malloc 和 mm_free 之前，必须通过调用 mm_init 函数来初始化堆。mm_init 函数从系统上的到 4 个字，并将它们初始化，创建一个空的空闲链表。然后调用 extend_heap 函数，这个函数将堆扩展 CHUNKSIZE 个字节，并且创建初始的空闲块。此刻分配器已初始化，并且准备好接受来自应用的分配和释放请求。

```c
/* 
 * mm_init - Initialize the memory manager 
 */
/* $begin mminit */
int mm_init(void) 
{
    /* Create the initial empty heap */
    if ((heap_listp = mem_sbrk(4*WSIZE)) == (void *)-1) //line:vm:mm:begininit
        return -1;
    PUT(heap_listp, 0);                          /* Alignment padding */
    PUT(heap_listp + (1*WSIZE), PACK(DSIZE, 1)); /* Prologue header */ 
    PUT(heap_listp + (2*WSIZE), PACK(DSIZE, 1)); /* Prologue footer */ 
    PUT(heap_listp + (3*WSIZE), PACK(0, 1));     /* Epilogue header */
    heap_listp += (2*WSIZE);                     //line:vm:mm:endinit  
    /* $end mminit */

#ifdef NEXT_FIT
    rover = heap_listp;
#endif
    /* $begin mminit */

    /* Extend the empty heap with a free block of CHUNKSIZE bytes */
    if (extend_heap(CHUNKSIZE/WSIZE) == NULL) 
        return -1;
    return 0;
}
/* $end mminit */
```

```c
/* 
 * extend_heap - Extend heap with free block and return its block pointer
 */
/* $begin mmextendheap */
static void *extend_heap(size_t words) 
{
    char *bp;
    size_t size;

    /* Allocate an even number of words to maintain alignment */
    size = (words % 2) ? (words+1) * WSIZE : words * WSIZE; //line:vm:mm:beginextend
    if ((long)(bp = mem_sbrk(size)) == -1)  
        return NULL;                                        //line:vm:mm:endextend

    /* Initialize free block header/footer and the epilogue header */
    PUT(HDRP(bp), PACK(size, 0));         /* Free block header */   //line:vm:mm:freeblockhdr
    PUT(FTRP(bp), PACK(size, 0));         /* Free block footer */   //line:vm:mm:freeblockftr
    PUT(HDRP(NEXT_BLKP(bp)), PACK(0, 1)); /* New epilogue header */ //line:vm:mm:newepihdr

    /* Coalesce if the previous block was free */
    return coalesce(bp);                                          //line:vm:mm:returnblock
}
/* $end mmextendheap */
```

extend_heap 函数会在两种不同的环境中被调用：

- 当对被初始化时
- 当 mm_malloc 不能找到一个合适的分配块时

extend_heap 将请求大小向上舍入为最接近 2 字的倍数，然后想内存系统请求额外的堆空间。extend_heap 的剩余部分有点微妙，堆开始于一个双字对齐的边界，并且每次对 extend_heap 的调用都会返回一个块，该块的大小是一个双字的整数倍。因此，对 mem_sbrk 的每次调用都返回一个双字对齐的内存片，紧接着跟在结尾块的头部后面。这个头部之后会变成新空闲块的头部，并且这个片的最后一个字变成了新的结尾块的头部。最后，在很可能出现的前一个堆以空闲块结束的情况中，我们调用 coalesce函数来合并两个空闲块，并返回最后合并的块的块指针。

#### （4）释放和合并块

应用通过调用 mm_free 函数，来释放一个以前分配的块，这个函数释放所请求的块，然后使用边界标记合并技术将之与邻接扽空闲块合并起来：

```c
/* 
 * mm_free - Free a block 
 */
/* $begin mmfree */
void mm_free(void *bp)
{
    /* $end mmfree */
    if (bp == 0) 
        return;

    /* $begin mmfree */
    size_t size = GET_SIZE(HDRP(bp));
    /* $end mmfree */
    if (heap_listp == 0){
        mm_init();
    }
    /* $begin mmfree */

    PUT(HDRP(bp), PACK(size, 0));
    PUT(FTRP(bp), PACK(size, 0));
    coalesce(bp);
}

/* $end mmfree */
/*
 * coalesce - Boundary tag coalescing. Return ptr to coalesced block
 */
/* $begin mmfree */
static void *coalesce(void *bp) 
{
    size_t prev_alloc = GET_ALLOC(FTRP(PREV_BLKP(bp)));
    size_t next_alloc = GET_ALLOC(HDRP(NEXT_BLKP(bp)));
    size_t size = GET_SIZE(HDRP(bp));

    if (prev_alloc && next_alloc) {            /* Case 1 */
        return bp;
    }

    else if (prev_alloc && !next_alloc) {      /* Case 2 */
        size += GET_SIZE(HDRP(NEXT_BLKP(bp)));
        PUT(HDRP(bp), PACK(size, 0));
        PUT(FTRP(bp), PACK(size,0));
    }

    else if (!prev_alloc && next_alloc) {      /* Case 3 */
        size += GET_SIZE(HDRP(PREV_BLKP(bp)));
        PUT(FTRP(bp), PACK(size, 0));
        PUT(HDRP(PREV_BLKP(bp)), PACK(size, 0));
        bp = PREV_BLKP(bp);
    }

    else {                                     /* Case 4 */
        size += GET_SIZE(HDRP(PREV_BLKP(bp))) + 
            GET_SIZE(FTRP(NEXT_BLKP(bp)));
        PUT(HDRP(PREV_BLKP(bp)), PACK(size, 0));
        PUT(FTRP(NEXT_BLKP(bp)), PACK(size, 0));
        bp = PREV_BLKP(bp);
    }
    /* $end mmfree */
#ifdef NEXT_FIT
    /* Make sure the rover isn't pointing into the free block */
    /* that we just coalesced */
    if ((rover > (char *)bp) && (rover < NEXT_BLKP(bp))) 
        rover = bp;
#endif
    /* $begin mmfree */
    return bp;
}
/* $end mmfree */
```

coalesce 函数中的代码是 图9-40 中勾画的四种情况的一种简单实现。这里也有一个微妙的方面，我们选择的空闲链表格式（它的序言块和结尾块总是被分配的）允许我们忽略潜在的麻烦边界情况，也就是，请求块 bp 在堆的起始处或者是在堆的结尾处。如果没有这些特殊块，代码将混乱得多，更慢更容易出错，因为不得不在每次释放请求时，都去检查这些不常见的边界情况。

#### （5）分配块

一个应用通过调用 mm_malloc 函数来向内存请求大小为 size 字节的块。在请求完请求的真假后，分配器必须调整请求块的大小，从而为头部和脚部预留空间，并满足双字对齐的要求。我们强制最小块大小是 16 字节：8字节用来满足对齐要求，另外 8 个字节用来存放头部和脚部。对于超过 8 字节的请求，一般的规则是加上开销字节，然后向上舍入到最接近 8 的整数倍。

```c
void *mm_malloc(size_t size) 
{
    size_t asize;      /* Adjusted block size */
    size_t extendsize; /* Amount to extend heap if no fit */
    char *bp;      

    /* $end mmmalloc */
    if (heap_listp == 0){
        mm_init();
    }
    /* $begin mmmalloc */
    /* Ignore spurious requests */
    if (size == 0)
        return NULL;

    /* Adjust block size to include overhead and alignment reqs. */
    if (size <= DSIZE)                                          //line:vm:mm:sizeadjust1
        asize = 2*DSIZE;                                        //line:vm:mm:sizeadjust2
    else
        asize = DSIZE * ((size + (DSIZE) + (DSIZE-1)) / DSIZE); //line:vm:mm:sizeadjust3

    /* Search the free list for a fit */
    if ((bp = find_fit(asize)) != NULL) {  //line:vm:mm:findfitcall
        place(bp, asize);                  //line:vm:mm:findfitplace
        return bp;
    }

    /* No fit found. Get more memory and place the block */
    extendsize = MAX(asize,CHUNKSIZE);                 //line:vm:mm:growheap1
    if ((bp = extend_heap(extendsize/WSIZE)) == NULL)  
        return NULL;                                  //line:vm:mm:growheap2
    place(bp, asize);                                 //line:vm:mm:growheap3
    return bp;
} 
/* $end mmmalloc */
```

一旦分配器调整了请求的大小，它就会搜索空闲链表，寻找一个合适的空闲块。如果有合适的，那么分配器就会放置这个请求块，并可选的分割出多余的部分，然后返回新分配的地址。

如果分配器不能够发现一个匹配的块，那么就用一个新的空闲块来扩展堆，把请求放进这个新的空闲块，可选的分割这个块，返回指向这个新分配块的指针。

### 13. 显式空闲链表

隐式空闲链表为我们提供了一种介绍一些基本分配器概念的简单方法。然而，因为块分配与堆块的总数成线性关系，所以对于通用的分配器，隐式空闲链表是不适用的。一种更好的方法是将空闲块组织为某种形式的显式数据结构，因为根据定义程序不需要一个空闲块的主体，所以实现这个数据结构的指针可以存放在这些空闲块的主体里。例如，堆可以组织成一个双向的空闲链表，在每一个空闲块中，都包含一个前驱（pred）和后驱（succ）指针：

![image-20231125173638736](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231125173638736.png)

使用双向空闲链表而不是隐式空闲链表，使首次适配的分配时间从块总数的线性时间减少到了空闲块数量的线性时间。不过释放一个块的时间可以是线性也可以是常数的，这取决于我们选择的空闲块链表中块的排序策略。

一种方法是用后进先出（LIFO）的顺序维护链表，将新释放的块放置在链表的开始处。使用 LIFO 的顺序和首次适配的方法，分配器会最先检查最近使用过的块。在这种情况下，释放一个块可以在常数时间内完成。如果使用了边界标记，那么合并也可以在常数时间内完成。

另一种方法是按照地址顺序来维护链表，其中链表的每个块的地址都小于它的后继地址。组这种情况下，释放一个块需要线性的时间来搜索定位合适的前驱。平衡点在于，按照地址排序的首次适配比 LIFO 排序的由更高的内存利用率，接近最佳适配的利用率。

一般而言，显式链表的缺点是空闲块必须足够大，以包含所需要的指针，以及头部和可能的脚部。这就导致更大的最小块大小，也潜在提高了内部碎片的程度。

### 14.分离的空闲链表

就像我们看到的那样，一个使用单向空闲块链表的分配器需要与空闲块数量成线性相关的时间来分配块。一种流行的减少分配时间的方法，通常称为分离存储（segregated storage），就是维护多个空闲链表，其中每个链表中的块有大致相等的大小。一般的思路是将所有可能的块大小分成一些等价类，也叫做大小类（size class）。有很多种方式来定义大小类，例如可以根据 2 的幂来划分块的大小：
$$
{\{1\}, \{2\}, \{3,4\}, \{5～8\}, ···,\{1025～2048\}, ···\{4096～\infty\}}
$$
或者可以将小块分派到它们自己的大小类里，而大块按照 2 的幂分类。有关动态内存分配的文献描述了十几种分离存储的方法，主要的区别在于如何让定义大小类，何时进行合并，何时向操作系统请求额外的堆内存，是否允许分割等等。简述两种方法：简单分离存储（simple segregated storage）和分离适配（segregated fit）。

#### （1）简单分离存储

使用简单分离存储，每个类的空闲链表包含大小相等的块，每个块的大小就是这个大小类中最大元素的大小。例如，某个定义的大小类为{17~32}，那么这个类的空闲链表全由大小为 32 的块组成。为了分配一个给定大小的块，我们检查相应的空闲链表，如果链表非空，我们简单的分配第一个块的全部。空闲块是不会分割以满足分配请求的。如果链表为空，分配器就向操作系统请求一个固定大小的额外内存片（通常是页的整数倍），将这个页分成大小相等的块，并将这些块链接起来形成一个新的空闲链表。要是释放一个块，分配器只要简单的讲这个块插入到相应空闲链表的前部。

优点：

分配是释放都是很快的常数时间操作。而且每个块大小相同，不分割不合并，这意味着每个块只有很少的内存开销。由于每个片只有大小相同的块，那么一个已分配的块的大小就可以从他的地址中推断出来。因为没有合并，所以已分配的头部就不需要一个已分配/空闲标记，又没有合并，所以不需要头部和脚部。因为分配和释放操作都是在空闲链表的起始处操作，所以链表只需要是单向的，而不用是双向的。关键点在于：在任何块中都需要的唯一字段是每个空闲块中一个字的指针（succ），因此最小块大小为 1 个字。

缺点：

简单分离容易造成内部和外部碎片。因为空闲块不会被分割，会造成内部碎片。不会合并，容易造成外部碎片。

#### （2）分离适配

使用这种方法，分配器维护着一个空闲链表数组。每个空闲链表都是和一个大小类相关联的，并且被组织成某种显式或者隐式链表。每个链表包含潜在的大小不同的块，这些块的大小是大小类的成员。有许多不同的分离适配器，这里描述一个简单的版本。

为了分配一个块，必须确定请求的大小类，并且对适当的空闲链表做首次适配，查找到一个合适的块。如果找到了，就可选的分割它，并将剩余部分插入到适当的空闲链表中。如果找不到合适的块，那么就搜索下一个更大的大小类的空闲链表，如此重复，知道找到一个合适的块。如果还是没有，就向操作系统请求额外的堆内存，从这个新的堆内存分配出一个块，将剩余的放入到一个合适的大小类中。要释放一个块，我们执行合并，并将结果放置到相应的空闲链表中。

分离适配是一种常见的选择，C 标准库中提供的 GNU malloc 包就是采用这种方法，既快速又有效，搜索被控制在堆的某一个范围，而不是一整个。其内存利用率近似于最佳适配搜索的利用率。

#### （3）伙伴系统

伙伴系统是分离适配的一个特例，其中每个类的大小都是 2 的幂。基本的思路是假设一个堆的大小为 2^m 个字，我们为每个块大小 2^k 维护一个空闲链表，其中 0<=k<=m。请求块大小由上舍入到最接近 2 的幂。最开始时，只有一个大小为 2^m 的空闲块。

为了分配一个大小为 2^k 的块，我们找到第一个可用的、大小为 2^j 的块，其中 k<=j<=m，如果 j=k，那么就完成，否则就递归的 2 分割这个块，直到 j=k。当我们进行这样的分割时，每个剩下的半块（也叫做伙伴），会被放置到相应的空闲链表中。要释放一个大小为 2^k 的块，我们继续合并空闲的伙伴，当遇到一个已分配的伙伴时，我们就停止合并。

关于伙伴系统的一个关键事实是，给定地址和块的大小，很容易计算出它的伙伴的地址。例如，一个块，大小 32 字节，地址为：0x*xxx···00000*，它的伙伴的地址为 ox*xxx···10000*，换句话说，两个伙伴的地址只有一位是不相同的。

优点：快速搜索和快速合并。

缺点：要求块大小是 2 的幂可能导致显著的内部碎片。

## 十、垃圾收集

在诸如 C malloc 包这样的显式分配器中国，应用通过调用 malloc 和 free 来分配和释放块。应用要负责释放所有不再需要的已分配块。未能释放已分配的块是一种常见的编程错误。垃圾收集器（garbage collector）是一种动态内存分配器，它自动释放程序不再需要的已分配块。这些块被称为垃圾（garbage）。自动回收堆存储的过程叫做垃圾收集。在一个支持垃圾收集的系统中，应用显式地分配内存，但从不显式地释放它们。我们的讨论局限于 Mark&Sweep（标记&清除）算法，这个算法很有趣，因为它可以建立在已存在的 malloc 包基础上，为 c 和 c++ 程序提供垃圾收集。

### 1. 垃圾收集器的基本知识

垃圾收集器将内存视为一张有向可达图（reachability graph），其形式如下图所示。该图的节点被分成一组根节点（root node）和一组堆节点（heap node）。每个堆节点对应于堆中的一个已分配块。有向边 p->q 意味着块 p 中的某个位置指向 q 中的个位置。根节点对应于这样一个不在堆中的位置，他们中包含指向堆中的指针。这些位置可以是寄存器、栈里的变量，或者是虚拟内存内读写数据区域内的全局变量。

![image-20231127142155872](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231127142155872.png)

当有一条从任意节点出发并到达 p 的有向路径时，我们说节点 p 是可达的。在任何时刻，不可达节点对应于垃圾，是不能被应用再次使用的。垃圾收集器的角色是维护可达图的某种表示，并通过释放不可达节点并将它们返回给空闲链表，来定期的回收它们。

像 ML 和 Java 这样的语言收集器，对应用如何创建和使用指针有很严格的控制，能够维护可达图的一种精确表示，因此能够回收所有的垃圾。然而，诸如 C 和 C++ 这样的语言的收集器通常不能维护可达图的精确表示。这样的收集器也叫做保守的垃圾收集器。从某种意义上说它们是保守的，即每个可达块都被正确的标记为可达了，而一些不可达节点却可能被错误的标记为可达。收集器可以按需提供它们的服务，或者可以作为一个和应用并行的独立线程，不断的更新可达图和回收垃圾。例如，考虑如何将一个 C 程序的保守的收集器加入到已存在的 malloc 包中，如下图所示：

![image-20231127143809697](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231127143809697.png)

无论何时应用需要堆空间时，应用都会用通常的方式调用 malloc。如果 malloc 找不到一个合适的空闲块，那么它就调用垃圾收集器，希望能够回收一些垃圾到空闲列表。收集器识别出垃圾块，，并通过调用 free 函数将它们返回给堆。关键思想收集器代理应用去代替 free。当对收集器的调用返回时，malloc 重试，如果还是失败，就向内核请求新的堆内存空间。最后，malloc 返回一个指向请求块的指针（成功）或者返回一个空指针（不成功）。

### 2. Mark&Sweep 垃圾收集器

Mark&Sweep 垃圾收集器由标记阶段和清除阶段组成。标记阶段标记出根节点的所有可达的和已分配的后继，而后面的清除阶段释放每一个未被标记的已分配块。块头部中的空闲的低位中的一位通常用来表示这个块是否被被标记。我们对 Mark&Sweep 的描述将假设使用下列函数，其中 ptr 被定义为 typedef void *ptr：

- ptr isPtr（ptr p）。如果 p 指向一个已分配块中的某个字，那么就返回一个指向这个块的起始位置的指针 b，否则返回 NULL。
- int blockMarked（ptr b）。如果块 b 是已标记的，那么就返回 true。
- int blockAllocated（ptr b）。如果块 b 是已分配的，那么就返回 true。
- void markBlock（ptr b）。标记块 b。
- int length（ptr b）。返回块 b 的以字为单位的长度（不包括 头部）。
- void unmarkBlock（ptr b）。将块 b 的状态从已标记改为未标记。
- ptr nextBlock（ptr b）。返回堆中块的后继。

标记阶段为每个根节点调用一次下图中所示的 mark 函数。如果 p 不指向一个已分配并且未标记的堆块，那么 mark 函数就立即返回。否则就标记这个堆块，并对这个块中的每个字递归的调用他自己。每次对 mark 函数的调用都标记某个根节点的所有未标记并且可达的后继节点。在标记阶段的末尾，任何未标记的已分配块都被认定为是不可达的，是垃圾，可以在清除阶段回收。

清除阶段是对下图的 sweep 函数的调用。sweep 函数在堆中的每个块上反复循环，释放它所遇到的所有未标记的已分配块。

下图展示了一个小堆的 Mark&Sweep 的图形化解释。块边界用粗线条表示。每个方块对应于内存中的一个字。每个块都有一个字的头部，要么是已标记的，要么是未标记的。

![image-20231127152251385](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231127152251385.png)

初始情况下，图中的堆由六个已分配块组成，其中每个块都是未标记的。第三块包含一个指向第 1 块的指针。第 4 块包含指向第 3 块和第 6 块的指针。根指向第 4 块。在标记阶段之后，第 1 块、第 3 块、第 4 块和第 6 块被做了标记，因为它们是从根节点可达的。第 2 块和第 5 块是未标记的，因为不可达。在清除阶段之后，这两个不可达块，被回收到空闲链表。

### 3. C 程序保守的 Mark&Sweep

Mark&Sweep对 C 程序的垃圾收集是一种合适的方法，因为他可以就地工作，而不需要移动任何块。然而，C 语言为 isPtr 函数的实现造成了一些有趣的挑战。

第一，C 不会用任何类型信息来标记内存位置。因此，对 isPtr 没有一种明显的方式来判断它的输入参数 p 是不是一个指针。第二，即使我们知道 p 是一个指针，对 isPtr 也没有明显的方式来判断 p 是否指向一个已分配块的有效载荷的某个位置。

对后一问题的解决方法是将已分配块集合维护成一颗平衡二叉树，这棵树保持着这样一个属性：左子树中的所有块都放在较小的地址处，而右指针的所有树都放在较大的地址处。如下图所示，这就要求每个已分配块的头部里面有两个附加的字段（left 和 right）。每个字段都指向某个已分配块的头部。isPtr（ptr p）函数用树来执行对已分配块的二分查找。在每一步中，它依赖于块头部中的大小字段来判断 p 是否落在这个块的范围之内。

![image-20231127190326304](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231127190326304.png)

平衡树方法保证会标记所有从根节点到达的节点，从这个意义上来说它是正确的。然而，这种方法从某种意义上而言又是保守的，因为它可能不会释放某些垃圾。虽然这不会影响程序的正确性，但是可能导致不必要的外部碎片。

C 语言的 Mark&Sweep 收集器必须是保守的，其根本原因是 C 语言不会用类型信息来标记内存位置。因此，像 int 或者 float 这样的标量可以伪装成指针。例如，假设某个可达的已分配块在它的有效载荷中包含一个 int，其值碰巧对应于某个其他已分配块 b 的有效载荷的一个地址。对于收集器而言，是没有办法推断出这个数据实际上是 int，而不是一个指针。因此，分配器必须保守的将块标记成可达，尽管它可能事实上是不可达的。

## 十一、C 语言常见的与内存有关的错误

对于 C 语言来说，管理和使用虚拟内存可能是一个困难的、容易出错的任务。与内存有关的错误属于那些最令人惊恐的错误，因为他们在时间和空间上，经常在距错误源一段距离后才表现出来。下面讨论几种常见的与内存有关的错误。

### 1. 间接引用坏指针

在进程的虚拟地址空间中有较大的洞，没有映射到任何有意义的数据。如果我们试图间接引用一个指向这些洞的指针，那么操作系统就会以段异常终止程序。而且虚拟内存的某些区域是只读的，试图写这些区域将会以保护异常终止这个程序。

### 2. 读未初始化的内存

虽然 bss内存位置（诸如未初始化的全局 C 变量）总是被加载器初始化为 0，但是对于堆内存不是这样的。一个常见的错误就是假设堆内存被初始化为 0：

![image-20231127200527425](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231127200527425.png)

在这个示例中，不正确的假设向量 y 被初始化为 0。正确的实现方式是显式的将 y[i] 设置为 0，或者使用 calloc。

### 3. 允许栈缓冲区溢出

如果一个程序不检查输入串的大小就写入栈中的目标缓冲区，那么这个程序就会有栈缓冲区溢出错误。例如，下面的函数会有栈缓冲区溢出错误，因为 gets 函数复制一个任意长度的串到缓冲区。为了纠正这个错误，我们需要使用 fgets 函数，这个函数限制了输入串的大小：

![image-20231127201407243](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231127201407243.png)

### 4. 假设指针和它们指向的对象是相同大小的

一种常见的错误是假设指向对象的指针和它们所指向的对象是相同大小的：

![image-20231127202207904](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231127202207904.png)

这里的目的是创建一个由 n 个指针组成的数组，每个指针都指向一个包含 m 个 int 的数组。然而，因为在第 5 行将 sizeof(int *) 写成了 sizeof(int) ，代码实际上创建的是一个 int 的数组。

这段代码只有在 int 和 指向 int 的指针大小相同的机器上运行良好。但是，如果我们在像 Core i7 这样的机器上运行这段代码，其中指针大于 int，那么第 7 行和第 8 行的循环将写到超出 A 数组的结尾。因为这些字中的一个很可能是已分配块的边界标记脚部，所以我们可能不会发现这个错误，直到这个程序在后面很久释放这个块时，可能会到你分配器中的合并代码戏剧性的失败。

### 5. 造成错位错误

错位错误是另一种很常见的造成覆盖错误的来源：

![image-20231127203018111](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231127203018111.png)

这是前面一节程序的另一个版本，在第 7 和第 8 行试图初始化这个数组的第 n + 1 个元素，这个过程会覆盖 A 数组后面的某个内存的位置。

### 6. 引用指针，而不是所指向的对象

如果不太注意 C 操作符中的优先级和结合性，我们就会错误的操作指针，而不是指针所指向的对象。比如考虑下面的函数，其目的是删除一个有 *size 项的二叉堆里的第一项，然后对剩下的 *size - 1 项重新建堆：

![image-20231128102156996](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231128102156996.png)

在第六行，目的是减少 size 指针指向的整数的值。然而，因为一元运算符 -- 和 * 的优先级相同，从右向左结合，所以第 6 行中的代码实际减少的是指针自己的值，而不是他所指向的整数的值。

### 7. 误解指针运算

另一种常见错误是忘记是忘记了指针的算术操作是以它指向的对象的大小为单位来进行的，而这种大小单位并不一定是字节。例如下面的函数的目的是扫描一个 int 数组，并返回一个指针，指向 val 的首次出现：

![image-20231128102658597](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231128102658597.png)

然而，因为每次循环时，第四行都把指针加了 4（一个整数的字节数），函数就不正确的扫描了数组中的每四个整数。

### 8. 引用不存在的变量

不理解栈的使用规则，有时会引用不再合法的本地变量，如下列所示：

![image-20231128102935787](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231128102935787.png)

这个函数返回一个指针（比如说是 p），指向栈里的一个局部变量，然后弹出他的栈帧。尽管 p 仍然指向一个合法内存地址，但是它不再指向一个合法的变量了，当以后在程序调用其他函数时，内存将重用它们的栈帧。再后来，如果程序分配某个值给 *p，那么实际可能在修改另一个函数的栈帧的一个条目，从而潜在的发生错误。

### 9. 引用空闲堆块中的数据

一个相似的错误是引用了被释放的堆块中的数据。例如，如下代码：

![image-20231128103732751](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231128103732751.png)

取决于第 6 行和第 10 行发生的 malloc 和 free 的调用模式，当程序在第 14 行引用 x[i] 时，数组 x 可能是某个其他已分配堆块的一部分，因此内容就被重写了。

### 10. 引起内存泄漏

当忘记释放已分配的块时，而在堆里产生了垃圾，就会导致内存泄漏了。对于像守护进程、服务器这样的程序来说，内存泄漏是十分严重的因为根据定义这些程序不会终止。