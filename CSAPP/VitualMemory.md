# 虚拟内存

一个系统中的进程是与其他进程共享 CPU 和主存资源的。然后共享主存会形成一些特殊的挑战。如果太多的进程需要太多的内存，那么他中的一些根本就无法运行。为了更加有效的管理内存并且少出错，现在系统提供了一种对主存的抽象概念，叫做虚拟内存（VM）。虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件的完美交互，它为每个进程提供了一个大的、一致的和私有的地址空间。

- 1. 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。
- 2. 它为每个进程提供了一致的地址空间，从而简化了内存管理。
- 3. 它保护了每个进程不被其他进程破坏。

## 一、物理和虚拟寻址

计算机系统的主存被组织成一个由 M 个连续的自己大小的单元组成的数组。每个字节都有一个唯一的物理地址（Physical Address，PA）。第一个字节的地址为 0，接下来的字节地址为 1，再下一个为 2，以此类推。给定这种简单的结构，CPU 访问内存的最自然的方式就是使用物理地址。这种方式称为 **物理寻址**。早期的 PC 使用物理寻址，现代处理器使用一种称为 **虚拟寻址**（virtual addressing）的寻址方式，如图所示：

![image-20231106220237996](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231106220237996.png)

使用虚拟寻址，CPU 会通过生成一个 虚拟地址 来访问主存，这个虚拟地址在被送到内存之前先转换成适当的物理地址。将一个虚拟地址转换为物理地址的任务叫做 **地址翻译**。就像异常处理一样，地址翻译需要 CPU 硬件和操作系统之间的紧密合作。CPU 芯片上叫做内存管理单元（Memory Management Unit， MMU）的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。

## 二、地址空间

地址空间（address space）是一个非负整数地址的有序集合：
$$
{\{0, 1, 2, ···\}}
$$
如果地址空间中的整数是连续的，那么我们说它是一个线性地址空间。为了简化讨论，假设使用的都是线性地址空间。在一个带虚拟内存的系统中，CPU 从一个有 N = 2^n 个地址的地址空间生成虚拟地址，这个地址空间称为虚拟地址空间：
$$
{\{0,1,2,···, N - 1\}}
$$
一个地址空间的大小是由表示最大地址所需要的位数来描述的。例如，一个包含 N = 2^n 个地址的虚拟地址空间就叫做一个 n 位地址空间。现代系统通常支持 32 位或者 64 位虚拟地址空间。

一个系统还有一个物理地址空间，对应于系统中物理内存的 M 个字节：
$$
{\{0,1,2,···, M - 1\}}
$$
M 不要求是 2 的幂，但是为了简化讨论，假设 M = 2^m。

地址空间的概念很重要，因为它清楚地区分了数据对象（字节）和他们的属性（地址）。一旦认识到了这种区别，那么我们就可以将其推广，允许每个数据对象有多个独立的地址，其中每个地址都选自一个不同的地址空间，这是虚拟内存的基本思想。主存中的每个字节都有一个选自虚拟地址空间的虚拟地址和选自物理地址空间的物理地址。

## 三、虚拟内存作为缓存的工具

概念上而言，虚拟内存被组织为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组。每字节都有一个唯一的虚拟地址，作为到数组的索引。磁盘上数组的内容被缓存到主存上。和存储器层次结构中的其他缓存一样，磁盘（较低层）上的数据被分割为块，这些快作为磁盘和主存（较高层）之间的传输单元。VM 系统通过将虚拟内存分割为称为**虚拟页（Virtual Page，VP）**的大小固定的块来处理这个问题。每个虚拟页的大小为 P = 2 ^ p 字节。类似的，物理内存被分割为**物理页（Physical Page，PP）**，大小也为 P 字节（物理页也被称为 页帧 ）。

在任意时刻，虚拟页面的集合都被分为三个不相交的子集：

- **未分配的：**VM 系统还未分配（或者创建）的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。
- **缓存的：**当前已缓存在物理内存中的已分配页。
- **未缓存的：**未缓存在物理内存中的已分配页。

下图展示了一个有 8 个虚拟页的小虚拟内存。虚拟页 0 和 3 还没有被分配，因此在磁盘上还不存在。虚拟页 1、4 和 6 被缓存在物理内存中。页 2、5 和 7 已经被分配了，但是当前还未缓存到主存中。

![image-20231106232739579](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231106232739579.png)

### 1. DRAM 缓存的组织结构

为了有助于清晰理解存储层次结构中不同的缓存概念，我们使用术语 **SRAM 缓存**来表示位于 CPU 和主存之间的 L1、L2 和 L3 高速缓存，并且用术语 DRAM 缓存来表示虚拟内存系统的缓存，他在主存中缓存虚拟页。

在存储层次结构中，DRAM 缓存的位置对它的组织结构有很大的影响。DRAM 比 SRAM 要慢大约 10 倍，而磁盘要比 DRAM 慢大约 100 000 多倍。因此，DRAM 缓存中的不命中比起 SRAM 缓存中的不命中要昂贵得多，这是因为 DRAM 缓存不命中要由磁盘来服务，而 SRAM 不命中通常由基于 DRAM 的主存来服务。而且，从磁盘的一个扇区读取第一个字节的时间开销比起读这个扇区中连续的字节要慢大约 100 000 倍。归根结底，DRAM 缓存的组织结构完全是由巨大的不命中开销驱动的。

因为巨大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是 4 KB ～ 2 MB。由于大的不命中处罚，DRAM 缓存是全相联的，即任何虚拟页都可以放置在任何物理页中。不命中的替换策略也很重要，因为替换错了虚拟页的处罚也非常之高。因此，与硬件对 SRAM 相比，操作系统对 DRAM 缓存使用了复杂精密的替换算法。最后，因为对磁盘访问的时间很长，DRAM 缓存总是使用写回，而不是直写。

### 2. 页表

同任何缓存一样，虚拟内存系统必须有某种办法来判定一个虚拟页是否缓存在 DRAM 中的某个地方。如果是，系统还必须确定这个虚拟页存放在哪个虚拟页中。如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页。

这些功能是由软硬件联合提供的，包括操作系统软件、MMU 中的地址翻译硬件和一个存放在物理内存中叫做**页表**的数据结构，页表将虚拟页映射到物理页。每次地址翻译将一个虚拟地址转换为物理地址时，都会读取页表。操作系统负责维护页表的内容，以及在磁盘与 DRAM 之间传送页。下图展示了一个页表的基本组织结构。页表就是一个页表条目（Page Table Entry，PTE）的数组。虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个 PTE。为了我们的目的，我们将假设每个 PTE 是由一个有效位和一个 n 位地址字段组成的。有效位表明了该虚拟页当前是否被缓存在 DRAM 中。如果设置了有效位，那么地址字段就表示 DTRAM 中相应的物理页的起始位置，这个物理页中缓存了该虚拟页。如果没有设置有效位，那么一个空地址表示这个虚拟页还没有被分配。否则，这个地址就指向该虚拟页在磁盘的起始位置。

图中展示了一个有 8 个虚拟页和 4 个物理页的系统的页表。四个虚拟页当前被缓存在 DRAM 中。两个页还没有被分配，而剩下的已经被分配了还没有被缓存。同时，还要注意，因为 DRAM 缓存时全相联的，所以任意物理页都可以包含任意虚拟页。

![image-20231107141326369](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107141326369.png)

### 3. 页命中

如下图所示，当 CPU 想要读取包含在 VP2 中的虚拟内存中的一个字时，如果 VP2 被缓存到 DRAM 中，使用地址翻译技术，地址翻译将虚拟地址作为一个索引来定位 PTE2，并在内存中读取它，因为设置了有效位，那么地址翻译硬件就知道 VP2 是缓存在内存中的，所以它使用 PTE 中的物理内存的地址（该地址指向 PP1 中缓存页的起始位置），构造出这个字的物理地址。

![image-20231107113516933](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107113516933.png)

### 4. 缺页

在虚拟内存的习惯说法中，DRAM 缓存不命中称为**缺页（page fault）**。下图展示了在缺页之前我们的示例页表的状态。CPU 引用了 VP3 中的一个字，VP3 并未缓存在 DRAM 中。地址翻译硬件从内存中读取 PTE3，从有效位推断出 VP3 未被缓存，并且触发一个缺页异常。缺页异常出发内核的缺页异常处理程序，该程序会选择一个牺牲页，在此示例中就是存放在 PP3 中的 VP4。如果 VP4 已经被修改了，那么内核就会将它复制回磁盘。无论哪种情况，内核都会修改 VP4 的页表条目，反映出 VP4 不再缓存在主存中这一事实。

![image-20231107114607922](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107114607922.png)

接下来，内核会从磁盘复制 VP3 到内存的 PP3 中，更新 PTE3，随后返回。当异常处理程序返回时，它会重新启动导致缺页的指令，该指令会把导致缺页的虚拟地址重发送到地址翻译硬件。但是现在，VP3 已经缓存到主存中了，那么页命中页命中也能由地址翻译硬件正常处理。，下图表示缺页之后的页表状态：

![image-20231107120126231](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107120126231.png)

虚拟内存系统使用了和 SRAM 缓存不同的术语，即使他们的许多概念是类似的。在虚拟内存的说法中，块被称之为页。在磁盘和内存之间传送页的活动叫做交换或者页面调度。页从磁盘换入 DRAM 和从 DRAM 换出磁盘。一直等待，直到最后时刻，也就是当有不命中发生时，才换入页面的这种策略称为按需页面调度。也可以采用其他的方法，例如尝试预测不命中，在页面实际被引用之前就换入页面。然后，所有现代系统都使用的是按需页面调度方式。

### 5. 分配页面

下图展示了操作系统分配一个新的虚拟内存页时对我们示例页表的影响，例如，调用 malloc 的结果。在这个示例中， VP5 的分配过程是在磁盘上创建空间并更新 PTE5，使它指向磁盘上新创建的页面。

![image-20231107141349552](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107141349552.png)

### 6. 局部性原理

我们了解了虚拟内存的概念以后，我们的第一印象通常是它的效率应该是非常低。因为不命中的处罚很大，我们担心页面调度会破坏程序的性能。实际上，虚拟内存工作的相当好，这主要归功于局部性原理。尽管在整个运行过程中程序引用的不同页面的总数可能超过物理内存的大小，但是局部性原则保证了在任意时刻，程序将趋向于在一个较小的活动页面的集合上工作，这个集合叫做工作集或者常驻集合。在初始开销，也就是将工作集页面调度到内存中之后，接下来对这个工作集的引用将导致命中，而不会产生额外的磁盘流量。只要程序有好的时间局部性，虚拟内存就会工作得相当好。但是，是不是所有程序都能展现良好的时间局部性，如果工作集的大小超出了物理内存的大小，那么程序就会产生一种不幸的状态，叫做抖动，这时页面将不断的换进换出。

## 四、虚拟内存作为内存管理的工具

到目前为止，我们都假设有一个单独的页表，将一个虚拟地址空间映射到物理地址空间。实际上，操作系统为每个进程提供了一个单独的页表，因而也就是一个独立的页表，因而也就是一个独立的虚拟地址空间。下图展示了基本思想。在这个示例中，进程 i 地页表将 VP1 映射到 PP2，VP2 映射到 PP7。相似地，进程 j 的页表将 VP1 映射到 PP7， VP2 映射到 PP10。注意，多个虚拟页面可以映射到同一个共享物理页面上。

![image-20231107141604674](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107141604674.png)

按需页面调度和独立的虚拟地址空间的结合，对系统中内存的使用和管理造成了深远的影响。特别地，VM 简化了链接和加载、代码和数据共享，以及应用程序的内存分配。

- 简化链接。独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。例如，一个给定的 Linux 系统上的每个进程都使用类似的内存格式。对于 64 位地址空间，代码段总是从虚拟地址 0x400000 开始。数据段跟在代码段之后，中间有一段符合要求的对齐空白。栈占据用户进程地址空间的最高的部分，并向下生长，这样的一致性极大的简化了链接器的设计和实现，允许链接器生成完全链接的可执行文件，这些可执行文件是独立于物理内存中代码和数据的最终位置的。

- 简化加载。虚拟内存还使得容易向内存中加载可执行文件和共享对象文件。要把目标文件中 .text 和 .data 节加载到一个新创建的进程中，Linux 加载器为代码和数据段分配虚拟页，把它们标记为无效的（即未被缓存的），将页表条目指向目标文件的适当位置。有趣的是，加载器从不从磁盘到内存实际复制任何数据。在每个页初次被引用时，要么是 CPU 取指令时引用的，要么是一条正在执行的指令引用一个内存位置时引用的。虚拟内存系统会按照需要自动地调入数据页。

    将一组连续的虚拟页映射到任意一个文件中的任意位置的表示方法叫做内存映射（mamory mapping）。Linux 提供一个称为 mmap 的系统调用，允许应用程序自己做内存映射。

- 简化共享。独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制。一般而言，每个进程都有自己私有的代码、数据、堆以及栈区域，是不和其他进程共享的。在这种情况中，操作系统创建页表，将相应的虚拟页映射到不连续的物理页面。

    然而，在一些情况下，还是需要进程来共享代码和数据。例如，每个进程必须调用相同的操作系统内核代码，而每个 c 程序都会调用 c 标准库中的程序，比如 printf。操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个副本，而不是每个进程都包括单独的内核和 c 标准库的副本。

- 简化内存分配。虚拟内存为向用户进程提供一个简单的分配额外内存的机制。当一个运行在用户进程中的程序要求额外的对空间时（如调用 malloc 的结果），操作系统分配一个适当数字（例如 k）个连续的虚拟内存页面，并且将它们映射到物理内存中任意位置的 k 个任意的物理页面。由于页表工作的方式，操作系统没有必要分配 k 个连续的物理内存页面。页面可以随机的分散在物理内存中。

## 五、虚拟内存作为内存保护的工具

任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问。不应该允许一个进程修改它的制度代码段。而且也不应该允许它读或者修改任何内核中的代码和数据结构。不应该允许它读或者写其他进程的私有内存，并且不允许它修改任何与其他进程共享的虚拟页面，除非所有的共享者都显式地允许它这么做（通过调用明确的进程间通信系统调用）。

就像我们所看到的，提供独立的地址空间使得区分不同进程的私有内存变得容易。但是，地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。因为每次 CPU 在生成一个地址时，地址翻译硬件都会读一个 PTE，所以通过在 PTE 上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单。如下图：

![image-20231107163141620](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107163141620.png)

在这个示例中，每个 PTE 中已经添加了三个许可位。SUP 位表示进程是否必须运行在内核（超级用户）模式下才能访问该页。运行在内核模式中的进程可以访问任何页面，但是运行在用户模式中的进程只允许访问那些 SUP 为 0 的页面。READ 位和 WRITE 位控制对页面的读和写访问。例如，如果进程 i 运行在用户模式下，那么它有读 VP0 和写 VP1 的权限，然后，不允许它访问 VP2。如果一条指令违反了这些许可条件，那么 CPU 就会触发一个保护故障，将控制传递给一个人内核中的异常处理程序，Linux shell 一般将这种异常报告为 **段错误（segment fault）**。

## 六、地址翻译

这一节讲述地址翻译的基础知识，目的是了解硬件在支持虚拟内存中的角色，并且给出足够多的细节使得可以亲手演示一些具体的示例。不过，这里省略了大量的细节，尤其是和时序相关的细节。下图包含了本节中要使用的所有符号：
![image-20231107193029468](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107193029468.png)

形式上来说，地址翻译是一个 N 元素的虚拟地址空间（VAS）中的元素和一个 M 元素的物理地址空间（PAS）中元素之间的映射，
$$
{MAP:VAS \rightarrow PAS\cup\emptyset}
$$
这里：

![image-20231107194224961](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107194224961.png)

下图展示了 MMU 如何利用页表来实现这种映射。CPU 中的一个控制寄存器，页表基址寄存器（Page Table Basic Register，PTBR）指向当前页表。n 位的虚拟地址包含两个部分：一个 p 位的虚拟页面偏移（Virtual Page Offset， VPO）和一个（n - p）位的虚拟页号（Virtual Page Number，VPN）。MMU 利用 VPN 来选择适当的 PTE。例如，VPN 0 选择 PTE 0，VPN 1 选择 PTE 1，以此类推。将页表条目的物理页号（PPN）和虚拟地址中的 VPO串联起来就得到对一个地址。注意，因为物理和虚拟页面都是 P 字节的，所以 PPO 和 VPO 也是相同的。

![image-20231107213205465](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107213205465.png)

下图展示了当页面命中和不命中时，CPU 硬件的执行步骤：

![image-20231107195905375](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107195905375.png)

当页面命中时：

1. 处理器生成一个虚拟地址，并把它传送给 MMU。
2. MMU 生成 PTE 地址，并从高速缓存/主存中请求得到它。
3. 高速缓存/主存向 MMU 返回 PTE。
4. MMU 构造物理地址，并把它传送给高速缓存/主存。
5. 高速缓存/主存返回请求的数据字给处理器。

当页面没有命中时：

1-3. 和命中时一样。

4. PTE 的有效位为 0，所以 MMU 出发一次异常，传递 CPU 中的控制到操作系统内核中的缺页异常处理程序。
5. 缺页处理程序确定出物理内存中的牺牲页，如果这个页面已经被修改了，则把它换出到磁盘。
6. 缺页处理程序页面调入新的页面，并更新内存中的 PTE。

### 1. 结合高速缓存和虚拟内存

在任何既使用虚拟内存又使用 SRAM 高速缓存的系统中，都有应该使用虚拟地址还是使用物理地址来访问 SRAM 高速缓存的问题。但是大多数系统还是选择物理寻址的。使用物理寻址，多个进程同时在高速缓存中有存储块和共享来自相同虚拟页面的块成为很简单的事情。而且，高速缓存无需处理保护问题，因为访问权限的检查是地址翻译的一部分。下图展示了一个物理寻址的高速缓存如何和虚拟内存结合起来。主要思路是地址翻译发生在高速缓存查找之前。注意，PTE 可以缓存，就像其他数据字一样。

![image-20231107213005648](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107213005648.png)

### 2. 利用 TLB 加速地址翻译

正如我们所看到的，每次 CPU 产生一个虚拟地址，MMU 就必须查阅一个 PTE，以便将虚拟地址翻译为物理地址。在最糟糕的情况下，这会要求从内存多取一次数据，代价是几十到几百个时钟周期。如果 PTE 碰巧缓存在 L1 中，那么开销就下降到 1～2 个时钟周期。然而，许多系统都试图消除即使是这样的开销，他们在 MMU 包括了一个关于 PTE 的小的缓存，称为 **翻译后备缓冲寄存器（Traslation Lookside Buffer，TLB）**。

![image-20231107212756729](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107212756729.png)

TLB 是一个小的、虚拟寻址的缓存，其中每一行都保存着一个由单个 PTE 组成的块。TLB 通常有高度的相联度。上图所示，用于组选择和行匹配的索引和标记字段是从虚拟地址中的虚拟页号中提取出来的。如果 TLB 有 T = 2^t 个组，那么 TLB 索引是由 VPN 的 t 个最低位组成的，而 TLB （TLBT）标记是由 VPN 中剩下的位组成的。

TLB 命中时的步骤：

1. CPU 产生一个虚拟地址。

2～3. MMU 从 TLB 中取出相应的 PLE。

4. MMU 将这个虚拟地址翻译成一个物理地址，并且将它发送到高速缓存/主存中。
5. 高速缓存/主存将所请求的数据字返回给 CPU。

当 TLB 不命中时，MMU 必须从 L1 缓存中取出相应的 PLE，如下图所示，新取的 PLE 放在 TLB 中，可能会覆盖一个已经存在的条目。

![image-20231107214338622](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231107214338622.png)

### 3. 多级页表

到目前为止，我们一直假设系统只用一个单独的页表来进行地址翻译，但是如果我们有一个 32 位的地址空间，4KB 的页面，和一个 4 字节的 PLE，那么即使应用所引用的只是虚拟地址空间中的很小一部分，也总是需要一个 4MB 的页表驻留在内存中，对于地址空间为 64 位的系统，则问题更加复杂。

用来压缩页表的常用方法是使用层次结构的页表。用一个具体的示例是容易理解这个思想的。假设 32 位虚拟地址空间被分为 4KB 的页，而每个页表条目都是 4 字节。还假设在这一时刻，虚拟地址有如下形式：内存的前 2k 个页面分配给了代码和数据，接下来 6k 个页面还未分配，再接下来 1023 个页面也未分配，接下来的一个页面被分配给用户栈，下图展示了如何为这个虚拟地址空间构造一个两级的页表层次结构：

![image-20231109114127307](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231109114127307.png)

一级页面中的每个 PTE 负责映射虚拟地址空间中一个 4MB 的片（chunk），这里的每一个片都是由 1024 个连续的页面组成的。比如， PTE0 映射第一片，PTE1 映射接下来的一片，以此类推。假设地址空间是 4GB，1024 个 PTE 已经足够覆盖整个空间了。如果片 i 中的每个页面都未被分配，那么一级 PTE i 就为空。例如上图，片 2～7 是未被分配的。然而，如果片 i 中至少有一个页是分配了的，那么一级 PTE i 就指向一个二级页表的基址。例如，在图中，片 0，1，8的所有或者部分已被分配，所以他们的一级 PTE 指向二级页表。

二级页面的每一个 PTE 都负责映射一个 4KB 的虚拟内存页面，就像我们查看只有一级的页表一样。注意，使用 4 字节的 PTE，每个一级和二级页表都是 4KB 字节，这刚好和一个页面大小是一样的。这种方法从两个方面减少了内存要求。第一，如果一级页表中的一个 PTE 是空的，那么相应的二级页表就根本不会存在。这代表着一种巨大的潜在节约，因为对于一个典型的程序，4GB 的虚拟地址空间大部分是未分配的。第二，只有一级页表才需要总是在内存中；虚拟内存系统可以在需要时创建、页面调入或调出二级页表，这就减少了主存的压力；只有最经常使用的二级页表才需要缓存在主存中。

下图描述了使用 k 级页表层次结构的地址翻译。虚拟地址被划分为称为 k 个 VPN 和一个 VPO。每个 VPN i 都是一个到第 i 级页表的索引，其中 1 <= i <= k。第 j 级页表中的每个 PTE，1 <= j <= k-1，都指向第 j+1 级某个页表的基址。第 k 级页表中的每个 PTE 包含某个物理界面的 PPN ，或者某个磁盘块的地址，为了构造物理地址，在能够确定 PPN 之前，MMU 必须访问 k 个 PTE。对于只有一级的页表结构，PPO 和 VPO 是相同的。

![image-20231109163207686](https://raw.githubusercontent.com/charming-c/image-host/master/img/image-20231109163207686.png)

### 4. 端到端的地址翻译

