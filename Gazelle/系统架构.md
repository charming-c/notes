# Gazelle 系统架构

## 一、总体架构

每一个 gazelle 进程持有一个 `protocol_stack_group`，启动的每一个协议栈线程 stack 共享:

```c
struct protocol_stack_group {
    uint16_t stack_num; // 协议栈数量
    uint16_t port_id;   // port id
    uint64_t rx_offload;
    uint64_t tx_offload;
    uint32_t reta_mask;
    uint16_t nb_queues;	// CPU 队列数量
    struct rte_mempool *kni_pktmbuf_pool;
    struct eth_params *eth_params;
    struct protocol_stack *stacks[PROTOCOL_STACK_MAX];  // 协议栈线程数组
    struct list_node  poll_list;	// poll_list 链表
    pthread_spinlock_t poll_list_lock;	// poll_list自旋锁
    sem_t sem_listen_thread;
    struct rte_mempool *total_rxtx_pktmbuf_pool[PROTOCOL_STACK_MAX]; // 分配的所有 dpdk mbuf 的数组
    sem_t sem_stack_setup;  // 启动的协议栈的数量（包括了协议栈线程和内核事件线程）信号量
    bool stack_setup_fail;  // 启动失败

    /* dfx stats */
    bool latency_start;
    uint64_t call_alloc_fail;
    pthread_spinlock_t socket_lock;	// socket 自旋锁
};
```
每一个线程都有一个协议栈结构，如下：
```c
struct protocol_stack {
    uint32_t tid;
    uint16_t queue_id;  // 每一个线程都分配一个 queue_id 
    uint16_t port_id;   // 端口 id
    uint16_t socket_id; // socket id
    uint16_t cpu_id;    // cpu id
    uint32_t stack_idx; // 协议栈的 index
    cpu_set_t idle_cpuset; /* idle cpu in numa of stack, app thread bind to it */
    int32_t epollfd; /* kernel event thread epoll fd */
    volatile enum rte_lcore_state_t state;

    struct rte_mempool *rxtx_mbuf_pool;
    struct rte_ring  *rx_ring;
    struct rte_ring *tx_ring;
    struct rte_ring *reg_ring;
    struct rte_ring *wakeup_ring;
    struct reg_ring_msg *reg_buf;
    uint32_t reg_head;

    volatile bool low_power;
    bool is_send_thread;

    char pad1 __rte_cache_aligned;
    rpc_queue dfx_rpc_queue;
    rpc_queue rpc_queue;
    char pad2 __rte_cache_aligned;

    /* kernel event thread read/write frequently */
    struct epoll_event kernel_events[KERNEL_EPOLL_MAX];
    int32_t kernel_event_num;
    char pad3 __rte_cache_aligned;

    struct netif netif;
    struct lstack_dev_ops dev_ops;
    uint32_t rx_ring_used;
    uint32_t tx_ring_used;

    struct rte_mbuf *pkts[NIC_QUEUE_SIZE_MAX];
    struct list_node recv_list;
    struct list_node same_node_recv_list; /* used for same node processes communication */
    struct list_node wakeup_list;

    volatile uint16_t conn_num;
    struct stats_ *lwip_stats;
    struct gazelle_stack_latency latency;
    struct gazelle_stack_stat stats;
    struct gazelle_stack_aggregate_stats aggregate_stats;
};
```



## 二、gazelle 进程初始化

大致的主体初始化流程：

<img src="/Users/charming/Library/Application Support/typora-user-images/image-20240708162235138.png" alt="image-20240708162235138" style="zoom: 50%;" />

**一些重要的全局配置**：

>  未设置收发分离时：
>
> num_cpu = num_queue
>
> 在设置收发分离时：
>
> num_queue = send_cpu_cnt * 2

## 三、线程初始化

### 1. stack_setup_thread

在 rtw 模式中 gazelle 会显式地开启 lstack 线程，线程数量等于 num_queue

- 在 num_queue 中，每一个 queue 对应一个线程

- 每一个线程都有一个这样的参数：

```c
struct thread_params {
    uint16_t queue_id;
    uint16_t idx;
};
```

**线程命名**：

1. 对于收发分离模式： 

    ret = sprintf_s(name, sizeof(name), "%s\_%d\_%d", LSTACK_RECV_THREAD_NAME, process_index, i / 2);

​       ret = sprintf_s(name, sizeof(name), "%s\_%d\_%d", LSTACK_SEND_THREAD_NAME, process_index, i / 2);

2. 对于普通模式：

​       ret = sprintf_s(name, sizeof(name), "%s", LSTACK_THREAD_NAME);

**线程参数设置**：

```c
i: 0..=num_queue
t_params[i]->idx = i;
t_params[i]->queue_id = process_index * queue_num + i;
```

### 2. gazelle_stack_thread

启动线程：



## 四、内存分配

### 1. stack_group_init_mempool 

进程启动后，主进程初始化分配 dpdk 内存池，保存在全局数据 stack_group 中。

**内存分配总量：**

根据配置中的 mbuf_count_per_conn * tcp_conn_count 申请需要分配 dpdk 的 mbuf 数量（此处应该是一个进程的数量）：

```c
uint32_t total_mbufs = get_global_cfg_params()->mbuf_count_per_conn * get_global_cfg_params()->tcp_conn_count;
```

根据 num_queue 将所有的 mbuf 总量平分，每次申请一个 pktmbuf 的大小为：

```c
rxtx_mbuf = create_pktmbuf_mempool(
                "rxtx_mbuf", 
  							total_mbufs / get_global_cfg_params()->num_queue, 
  							RXTX_CACHE_SZ, 
  							queue_id, 
  							numa_id);
```

**pktmbuf 命名为：**```"rxtx_mbuf_{$queue_id}"```

**queue_id 的设置：**` queue_id = cpu_idx * global_cfg_parmas->num_process + process_idx;`

<img src="/Users/charming/Library/Application Support/typora-user-images/image-20240708155921007.png" alt="image-20240708155921007" style="zoom: 33%;" />

